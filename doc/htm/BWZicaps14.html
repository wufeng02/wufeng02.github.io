<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8"/>
        <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
        <meta name="viewport" content="width=device-width, initial-scale=1"/>
       
        <meta name="robots" content="NOODP"/>
        <meta name="msvalidate.01" content="7662302B2EE2DF855D33DA34FD827164"/>
        <meta name="google-site-verification" content="Nj_dp8eZCY7mCHa7wHJz4MXpILpTh7vii2xAujBW5Zg"/>

        <meta name="author" content="Aijun Bai, Feng Wu, Zongzhang Zhang, Xiaoping Chen" />
        <meta name="description" content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems." />
        
        <title>Thompson Sampling based Monte-Carlo Planning in POMDPs</title>
        <link rel="icon" href="//wufeng02.github.io/media/favicon.ico" type="image/x-icon"/>
        <link rel="shortcut icon" href="//wufeng02.github.io/media/favicon.ico" type="image/x-icon"/>

        <!-- Bootstrap core CSS -->
        <link href="//wufeng02.github.io/static/bootstrap/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
        <!-- Custom styles for this template -->
        <style type="text/css">
            
            pre { white-space:pre-wrap;  }
        </style>
        
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]-->
    </head>
    <body>

        <br/>
        <div class="container">
            <ol class="breadcrumb">
                <li style="width: auto;">
                    <a href="//wufeng02.github.io/publication.html">Publication</a>
                </li>
                <li class="active" style="width: 90%;">
                    
                    Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS),
                    
                    
                    
        Page 29-37, Portsmouth, United States, 2014.         </li>
            </ol>
        
            <h3 class="text-center">
                Thompson Sampling based Monte-Carlo Planning in POMDPs
            </h3>
        
            <p class="text-center">
                Aijun Bai, Feng Wu, Zongzhang Zhang, Xiaoping Chen
            </p>
            
            <h4 class="page-header">Abstract</h4>
            <p>Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems.</p>
        
            <a href="//wufeng02.github.io/doc/pdf/BWZicaps14.pdf">
                Read More
            </a>
        
            <h4 class="page-header">BibTex</h4>
            <pre><code>@inproceedings{BWZicaps14,
         address = {Portsmouth, United States},
         author = {Aijun Bai and Feng Wu and Zongzhang Zhang and Xiaoping Chen},
         booktitle = {Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)},
         pages = {29-37},
         title = {Thompson Sampling based Monte-Carlo Planning in {POMDPs}},
         year = {2014}
        }
        
        </code></pre>
        </div>
        <footer class="text-center">
            <script type="text/javascript">
                var e = 'wu'+'feng'+'02'+'@'+'ustc'+'.'+'edu'+'.'+'cn';
                document.writeln('<a href="mail'+'to:'+e+'">'+e+'</a>');
            </script>
            <noscript>
                <img src="//wufeng02.github.io/img/email.png" alt="Email"/>
            </noscript>
        </footer>
        <br/>
        <script src="//wufeng02.github.io/static/jquery/jquery.min.js" type="text/javascript"></script>
        <script src="//wufeng02.github.io/static/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
 
        <script type="text/javascript">
            $(function() {
                $.queries = {};
                var params = window.location.search.substring(1).split('&');
                for (var i = 0; i < params.length; ++i) {
                    var pair = params[i].split('=');
                    $.queries[decodeURIComponent(pair[0])] = decodeURIComponent(pair[1] || '');
                }

                $('code').each(function(){
                  var text = $(this).text().replace(/^\s+/gm, '\t')
                    .replace(/\t}/gm, '}').replace(/([^,])\n\t/gm, '$1 ');
                  $(this).text(text);
                });
            });
        </script>
        <script type="text/javascript">
            (function(i,s,o,g,r,a,m){i['Go'+'og'+'le'+'AnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.go'+'og'+'le'+'-analytics.com/analytics.js','ga');
        
            ga('create', 'UA-31597550-1', 'auto');
            ga('send', 'pageview');
        
            $('a').not('[href^="javascript"]').click(function(e) {
                ga('send', 'event', 'link', 'click', $(this).attr('href'));
            });
        </script>
        <script type="application/ld+json">
        {
          "@context": "http://schema.org",
          "@type": "WebSite",
          "name": "Feng Wu (吴锋)",
          "url": "//wufeng02.github.io/",
          "potentialAction": {
            "@type": "SearchAction",
            "target": "//wufeng02.github.io/search.html?q={search_term_string}",
            "query-input": "required name=search_term_string"
          }
        }
        </script>
	</body>
</html>