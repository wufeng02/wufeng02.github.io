<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=7662302B2EE2DF855D33DA34FD827164><meta name=google-site-verification content=Nj_dp8eZCY7mCHa7wHJz4MXpILpTh7vii2xAujBW5Zg><title>Feng Wu (吴锋) | Thompson Sampling based Monte-Carlo Planning in POMDPs</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta name=citation_author content="Aijun Bai"><meta name=citation_author content="Feng Wu"><meta name=citation_author content="Zongzhang Zhang"><meta name=citation_author content="Xiaoping Chen"><meta name=citation_book_title content="Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=citation_inbook_title content="Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=citation_conference_title content="The 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=citation_conference content="The 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=citation_firstpage content=29><meta name=citation_lastpage content=37><meta name=citation_publication_date content=2014><meta name=citation_online_date content=2014><meta name=citation_date content=2014><meta name=citation_year content=2014><meta name=citation_pdf_url content=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf><meta name=citation_abstract content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><meta name=bepress_citation_title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta name=bepress_citation_author content="Aijun Bai"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_author content="Zongzhang Zhang"><meta name=bepress_citation_author content="Xiaoping Chen"><meta name=bepress_citation_book_title content="Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=bepress_citation_firstpage content=29><meta name=bepress_citation_lastpage content=37><meta name=bepress_citation_date content=2014><meta name=bepress_citation_online_date content=2014><meta name=bepress_citation_pdf_url content=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf><meta name=bepress_citation_abstract_html_url content=//wufeng02.github.io/doc/htm/BWZicaps14.html><meta name=bepress_citation_abstract content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><meta name=eprints.source content=//wufeng02.github.io/doc/htm/BWZicaps14.html><meta name=eprints.title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta name=eprints.creators_name content="Aijun Bai"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.creators_name content="Zongzhang Zhang"><meta name=eprints.creators_name content="Xiaoping Chen"><meta name=eprints.type content=conference_item><meta name=eprints.event_type content=conference><meta name=eprints.event_title content="Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=eprints.date content=2014><meta name=eprints.date_type content=published><meta name=eprints.document_url content=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf><meta name=eprints.citation content="Aijun Bai, Feng Wu, Zongzhang Zhang, Xiaoping Chen. Thompson Sampling based Monte-Carlo Planning in POMDPs. In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS), pages 29-37, Portsmouth, United States, June 2014."><meta name=eprints.abstract content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=//wufeng02.github.io/doc/htm/BWZicaps14.html><meta name=DC.title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta name=DC.creator content="Aijun Bai"><meta name=DC.creator content="Feng Wu"><meta name=DC.creator content="Zongzhang Zhang"><meta name=DC.creator content="Xiaoping Chen"><meta name=DC.type content="Conference or Workshop Item"><meta name=DC.relation.ispartof content="Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)"><meta name=DC.citation.spage content=29><meta name=DC.citation.epage content=37><meta name=DC.issued content=2014><meta name=DC.date content=2014><meta name=DC.format content=application/pdf><meta name=DC.identifier content=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf><meta name=DC.description content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><meta name=twitter:site content=//wufeng02.github.io/doc/htm/BWZicaps14.html><meta property=twitter:title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta property=twitter:description content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><meta property=og:site_name content=//wufeng02.github.io/doc/htm/BWZicaps14.html><meta property=og:title content="Thompson Sampling based Monte-Carlo Planning in POMDPs"><meta property=og:url content=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf><meta property=og:description content="Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems."><link rel=canonical href=//wufeng02.github.io/doc/htm/BWZicaps14.html><link rel=alternate hreflang=x-default href=//wufeng02.github.io/doc/htm/BWZicaps14.html><link rel=alternate hreflang=en href="//wufeng02.github.io/doc/htm/BWZicaps14.html?lang=en"><link rel=alternate hreflang=zh href="//wufeng02.github.io/doc/htm/BWZicaps14.html?lang=zh"><link rel=search type=text/html href=//wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=//wufeng02.github.io/search.xml><link rel=icon href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=//wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=//wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=//wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=//wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_book_title itemprop=name>Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)</span>, </span> Page <span itemprop=pagination>29-37</span>, <span class="citation_date citation_year" itemprop=datePublished>2014</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Thompson Sampling based Monte-Carlo Planning in POMDPs </h1><h3 id=author class=citation_author><span itemprop=author> Aijun Bai</span>, <span itemprop=author>Feng Wu</span>, <span itemprop=author>Zongzhang Zhang</span>, <span itemprop=author>Xiaoping Chen </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems.</p> &raquo; <a href=//wufeng02.github.io/doc/pdf/BWZicaps14.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 353.2KB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Aijun Bai</span>, <span class=cite_a>Feng Wu</span>, <span class=cite_a>Zongzhang Zhang</span>, <span class=cite_a>Xiaoping Chen</span>. <span class=cite_t>Thompson Sampling based Monte-Carlo Planning in POMDPs</span>. In <span class=cite_p>Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)</span>, <span class=cite_s>pages 29-37</span>, <span class=cite_l>Portsmouth, United States,</span> <span class=cite_m>June </span><span class=cite_y>2014</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=//wufeng02.github.io/doc/htm/BWZicaps14.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@inproceedings</span><span class=p>{</span><span class=nl>BWZicaps14</span><span class=p>,</span>
 <span class=na>address</span> <span class=p>=</span> <span class=s><span class=p>{</span>Portsmouth, United States<span class=p>}</span></span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Aijun Bai and Feng Wu and Zongzhang Zhang and Xiaoping Chen<span class=p>}</span></span><span class=p>,</span>
 <span class=na>booktitle</span> <span class=p>=</span> <span class=s><span class=p>{</span>Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>month</span> <span class=p>=</span> <span class=s><span class=p>{</span>June<span class=p>}</span></span><span class=p>,</span>
 <span class=na>pages</span> <span class=p>=</span> <span class=s><span class=p>{</span>29-37<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Thompson Sampling based Monte-Carlo Planning in POMDPs<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2014<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Thompson+Sampling+based+Monte-Carlo+Planning+in+POMDPs" target=_blank>Google Scholar</a> &mdash; Cited by <a href="https://scholar.google.com/scholar?oi=bibs&hl=ja&cites=12424774836954384724" target=_blank>11</a></li><li><a href="https://search.crossref.org/?q=Thompson+Sampling+based+Monte-Carlo+Planning+in+POMDPs" target=_blank>Crossref</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a> &mdash; Accession Number: 20152600983702 </li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=//wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=//wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=//wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>