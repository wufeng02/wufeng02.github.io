<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=7662302B2EE2DF855D33DA34FD827164><meta name=google-site-verification content=Nj_dp8eZCY7mCHa7wHJz4MXpILpTh7vii2xAujBW5Zg><title>Feng Wu (吴锋) | ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta name=citation_author content="Shanghong Li"><meta name=citation_author content="Yongquan Chen"><meta name=citation_author content="Long Xu"><meta name=citation_author content="Jun Luo"><meta name=citation_author content="Rui Huang"><meta name=citation_author content="Feng Wu"><meta name=citation_author content="Yingliang Miao"><meta name=citation_journal_title content="IEEE Transactions on Circuits and Systems for Video Technology"><meta name=citation_journal_abbrev content="IEEE TCSVT"><meta name=citation_publication_date content=2024><meta name=citation_online_date content=2024><meta name=citation_date content=2024><meta name=citation_year content=2024><meta name=citation_pdf_url content=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf><meta name=citation_abstract content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><meta name=bepress_citation_title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta name=bepress_citation_author content="Shanghong Li"><meta name=bepress_citation_author content="Yongquan Chen"><meta name=bepress_citation_author content="Long Xu"><meta name=bepress_citation_author content="Jun Luo"><meta name=bepress_citation_author content="Rui Huang"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_author content="Yingliang Miao"><meta name=bepress_citation_journal_title content="IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)"><meta name=bepress_citation_date content=2024><meta name=bepress_citation_online_date content=2024><meta name=bepress_citation_pdf_url content=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf><meta name=bepress_citation_abstract_html_url content=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><meta name=bepress_citation_abstract content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><meta name=eprints.source content=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><meta name=eprints.title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta name=eprints.creators_name content="Shanghong Li"><meta name=eprints.creators_name content="Yongquan Chen"><meta name=eprints.creators_name content="Long Xu"><meta name=eprints.creators_name content="Jun Luo"><meta name=eprints.creators_name content="Rui Huang"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.creators_name content="Yingliang Miao"><meta name=eprints.type content=article><meta name=eprints.publication content="IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)"><meta name=eprints.date content=2024><meta name=eprints.date_type content=published><meta name=eprints.document_url content=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf><meta name=eprints.citation content="Shanghong Li, Yongquan Chen, Long Xu, Jun Luo, Rui Huang, Feng Wu, Yingliang Miao. ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter. IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT), 2024."><meta name=eprints.abstract content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><meta name=DC.title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta name=DC.creator content="Shanghong Li"><meta name=DC.creator content="Yongquan Chen"><meta name=DC.creator content="Long Xu"><meta name=DC.creator content="Jun Luo"><meta name=DC.creator content="Rui Huang"><meta name=DC.creator content="Feng Wu"><meta name=DC.creator content="Yingliang Miao"><meta name=DC.type content=Article><meta name=DC.relation.ispartof content="IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)"><meta name=DC.issued content=2024><meta name=DC.date content=2024><meta name=DC.format content=application/pdf><meta name=DC.identifier content=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf><meta name=DC.description content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><meta name=twitter:site content=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><meta property=twitter:title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta property=twitter:description content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><meta property=og:site_name content=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><meta property=og:title content="ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter"><meta property=og:url content=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf><meta property=og:description content="Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods."><link rel=canonical href=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><link rel=alternate hreflang=x-default href=//wufeng02.github.io/doc/htm/LCXitcsvt24.html><link rel=alternate hreflang=en href="//wufeng02.github.io/doc/htm/LCXitcsvt24.html?lang=en"><link rel=alternate hreflang=zh href="//wufeng02.github.io/doc/htm/LCXitcsvt24.html?lang=zh"><link rel=search type=text/html href=//wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=//wufeng02.github.io/search.xml><link rel=icon href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=//wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=//wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=//wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=//wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_journal_title itemprop=name>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</span>, </span><span class="citation_date citation_year" itemprop=datePublished>2024</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter </h1><h3 id=author class=citation_author><span itemprop=author> Shanghong Li</span>, <span itemprop=author>Yongquan Chen</span>, <span itemprop=author>Long Xu</span>, <span itemprop=author>Jun Luo</span>, <span itemprop=author>Rui Huang</span>, <span itemprop=author>Feng Wu</span>, <span itemprop=author>Yingliang Miao </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>Click-based interactive segmentation is the most concise and widely used data labeling method. While existing interactive segmentation methods excel in handling simple targets, they encounter challenges in obtaining high-quality masks from some complex scenes, even with a large number of clicks. Also, the cost of retraining the model from scratch for special scenarios is unacceptably high. To address these issues, we propose ClickAdapter, a simple yet powerful interactive segmentation model adapter without the need for no pre-training. Through introducing a small number of additional parameters and computations, the adapter module effectively enhanced the ability of interactive segmentation models to obtain high-quality prediction with limited clicks. Specifically, we incorporate a detail extractor that aims to extract spatial correlations and local detail features of images. These fine-grained data are then integrated into a model with our adapter to generate segmentation masks with sharp and precise edges. During the training process, only the parameters of our adapter are learnable, thereby reducing the training cost. Features in special scenarios can also be infused more efficiently. To verify the efficiency and performance advantages of the proposed method, a series of experiments on a wide range of benchmarks were conducted, demonstrating that the proposed algorithm achieved cutting-edge performance compared to current state-of-the-art (SOTA) methods.</p> &raquo; <a href=//wufeng02.github.io/doc/pdf/LCXitcsvt24.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 9.7MB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Shanghong Li</span>, <span class=cite_a>Yongquan Chen</span>, <span class=cite_a>Long Xu</span>, <span class=cite_a>Jun Luo</span>, <span class=cite_a>Rui Huang</span>, <span class=cite_a>Feng Wu</span>, <span class=cite_a>Yingliang Miao</span>. <span class=cite_t>ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter</span>. <span class=cite_p>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</span>, <span class=cite_y>2024</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=//wufeng02.github.io/doc/htm/LCXitcsvt24.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@article</span><span class=p>{</span><span class=nl>LCXitcsvt24</span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Shanghong Li and Yongquan Chen and Long Xu and Jun Luo and Rui Huang and Feng Wu and Yingliang Miao<span class=p>}</span></span><span class=p>,</span>
 <span class=na>journal</span> <span class=p>=</span> <span class=s><span class=p>{</span>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>ClickAdapter: Integrating Details into Interactive Segmentation Model with Adapter<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2024<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=ClickAdapter:+Integrating+Details+into+Interactive+Segmentation+Model+with+Adapter" target=_blank>Google Scholar</a></li><li><a href="https://search.crossref.org/?q=ClickAdapter:+Integrating+Details+into+Interactive+Segmentation+Model+with+Adapter" target=_blank>Crossref</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=//wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=//wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=//wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>