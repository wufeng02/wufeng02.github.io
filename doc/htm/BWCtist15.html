<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8"/>
        <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
        <meta name="viewport" content="width=device-width, initial-scale=1"/>
       
        <meta name="robots" content="NOODP"/>
        <meta name="msvalidate.01" content="7662302B2EE2DF855D33DA34FD827164"/>
        <meta name="google-site-verification" content="Nj_dp8eZCY7mCHa7wHJz4MXpILpTh7vii2xAujBW5Zg"/>

        <meta name="author" content="Aijun Bai, Feng Wu, Xiaoping Chen" />
        <meta name="description" content="Markov decision processes (MDPs) provide a rich framework for planning under uncertainty. However, exactly solving a large MDP is usually intractable due to the ''curse of dimensionality'' - the state space grows exponentially with the number of state variables. Online algorithms tackle this problem by avoiding computing a policy for the entire state space. On the other hand, since online algorithm has to find a near-optimal action online in almost real time, the computation time is often very limited. In the context of reinforcement learning, MAXQ is a value function decomposition method that exploits the underlying structure of the original MDP and decomposes it into a combination of smaller subproblems arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in online settings. Compared to traditional online planning algorithms, MAXQ-OP is able to reach much more deeper states in the search tree with relatively less computation time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the effectiveness of our approach. We have also conducted a long-term case study in a highly complex simulated soccer domain and developed a team named WrightEagle that has won five world champions and five runners-up in the recent 10 years of RoboCup Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm the scalability of MAXQ-OP to very large domains." />
        
        <title>Online Planning for Large Markov Decision Processes with Hierarchical Decomposition</title>
        <link rel="icon" href="/img/favicon.ico" type="image/x-icon"/>
        <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon"/>

        <!-- Bootstrap core CSS -->
        <link href="/lib/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
        <!-- Custom styles for this template -->
        <style type="text/css">
            
            pre { white-space:pre-wrap;  }
        </style>
        
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]-->
    </head>
    <body>

        <br/>
        <div class="container">
            <ol class="breadcrumb">
                <li style="width: auto;">
                    <a href="/publication.html">Publication</a>
                </li>
                <li class="active" style="width: 90%;">
                    ACM Transactions on Intelligent Systems and Technology (ACM TIST),
                    
                    
                    
                    
        Volume 6(4), Number 45, August, 2015.         </li>
            </ol>
        
            <h3 class="text-center">
                Online Planning for Large Markov Decision Processes with Hierarchical Decomposition
            </h3>
        
            <p class="text-center">
                Aijun Bai, Feng Wu, Xiaoping Chen
            </p>
            
            <h4 class="page-header">Abstract</h4>
            <p>Markov decision processes (MDPs) provide a rich framework for planning under uncertainty. However, exactly solving a large MDP is usually intractable due to the ''curse of dimensionality'' - the state space grows exponentially with the number of state variables. Online algorithms tackle this problem by avoiding computing a policy for the entire state space. On the other hand, since online algorithm has to find a near-optimal action online in almost real time, the computation time is often very limited. In the context of reinforcement learning, MAXQ is a value function decomposition method that exploits the underlying structure of the original MDP and decomposes it into a combination of smaller subproblems arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in online settings. Compared to traditional online planning algorithms, MAXQ-OP is able to reach much more deeper states in the search tree with relatively less computation time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the effectiveness of our approach. We have also conducted a long-term case study in a highly complex simulated soccer domain and developed a team named WrightEagle that has won five world champions and five runners-up in the recent 10 years of RoboCup Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm the scalability of MAXQ-OP to very large domains.</p>
        
            <a href="/doc/pdf/BWCtist15.pdf">
                Read More
            </a>
        
            <h4 class="page-header">BibTex</h4>
            <pre><code>@article{BWCtist15,
         author = {Aijun Bai and Feng Wu and Xiaoping Chen},
         journal = {ACM Transactions on Intelligent Systems and Technology (ACM TIST)},
         month = {August},
         number = {45},
         title = {Online Planning for Large Markov Decision Processes with Hierarchical Decomposition},
         volume = {6(4)},
         year = {2015}
        }
        
        </code></pre>
        </div>
        <footer class="text-center">
            <script type="text/javascript">
                var e = 'wu'+'feng'+'02'+'@'+'ustc'+'.'+'edu'+'.'+'cn';
                document.writeln('<a href="mail'+'to:'+e+'">'+e+'</a>');
            </script>
            <noscript>
                <img src="/img/email.png" alt="Email"/>
            </noscript>
        </footer>
        <br/>
        <script src="/lib/jquery/jquery-1.12.0.min.js" type="text/javascript"></script>
        <script src="/lib/bootstrap/3.3.6/js/bootstrap.min.js" type="text/javascript"></script>
 
        <script type="text/javascript">
            (function($) {
                $.queries = {};
                var params = window.location.search.substring(1).split('&');
                for (var i = 0; i < params.length; ++i) {
                    var pair = params[i].split('=');
                    $.queries[decodeURIComponent(pair[0])] = 
                        decodeURIComponent(pair[1] || '');
                }

                $('code').each(function(){
                  var text = $(this).text().replace(/^\s+/gm, '\t')
                    .replace(/\t}/gm, '}').replace(/([^,])\n\t/gm, '$1 ');
                  $(this).text(text);
                });
            })(jQuery);
        </script>
        <script type="text/javascript">
            (function(i,s,o,g,r,a,m){i['Go'+'og'+'le'+'AnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.go'+'og'+'le'+'-analytics.com/analytics.js','ga');
        
            ga('create', 'UA-31597550-1', 'auto');
            ga('send', 'pageview');
        
            $('a').not('[href^="javascript"]').click(function(e) {
                ga('send', 'event', 'link', 'click', $(this).attr('href'));
            });
        </script>
        <script type="application/ld+json">
        {
          "@context": "http://schema.org",
          "@type": "WebSite",
          "name": "Feng Wu (吴锋)",
          "url": "/",
          "potentialAction": {
            "@type": "SearchAction",
            "target": "/search.html?q={search_term_string}",
            "query-input": "required name=search_term_string"
          }
        }
        </script>
	</body>
</html>