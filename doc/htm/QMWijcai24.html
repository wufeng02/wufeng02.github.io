<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=n/a><meta name=google-site-verification content=TlGo1hAtAmt_Rcaql8ze8OrWwroTFpl2bfmPzbysQkY><title>Feng Wu (吴锋) | Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta name=citation_author content="Yang Qu"><meta name=citation_author content="Jinming Ma"><meta name=citation_author content="Feng Wu"><meta name=citation_book_title content="Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=citation_inbook_title content="Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=citation_conference_title content="The Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=citation_conference content="The Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=citation_firstpage content=184><meta name=citation_lastpage content=192><meta name=citation_publication_date content=2024><meta name=citation_online_date content=2024><meta name=citation_date content=2024><meta name=citation_year content=2024><meta name=citation_pdf_url content=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf><meta name=citation_abstract content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><meta name=bepress_citation_title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta name=bepress_citation_author content="Yang Qu"><meta name=bepress_citation_author content="Jinming Ma"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_book_title content="Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=bepress_citation_firstpage content=184><meta name=bepress_citation_lastpage content=192><meta name=bepress_citation_date content=2024><meta name=bepress_citation_online_date content=2024><meta name=bepress_citation_pdf_url content=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf><meta name=bepress_citation_abstract_html_url content=https://wufeng02.github.io/doc/htm/QMWijcai24.html><meta name=bepress_citation_abstract content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><meta name=eprints.source content=https://wufeng02.github.io/doc/htm/QMWijcai24.html><meta name=eprints.title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta name=eprints.creators_name content="Yang Qu"><meta name=eprints.creators_name content="Jinming Ma"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.type content=conference_item><meta name=eprints.event_type content=conference><meta name=eprints.event_title content="Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=eprints.date content=2024><meta name=eprints.date_type content=published><meta name=eprints.document_url content=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf><meta name=eprints.citation content="Yang Qu, Jinming Ma, Feng Wu. Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control. In Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI), pages 184-192, 2024."><meta name=eprints.abstract content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=https://wufeng02.github.io/doc/htm/QMWijcai24.html><meta name=DC.title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta name=DC.creator content="Yang Qu"><meta name=DC.creator content="Jinming Ma"><meta name=DC.creator content="Feng Wu"><meta name=DC.type content="Conference or Workshop Item"><meta name=DC.relation.ispartof content="Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)"><meta name=DC.citation.spage content=184><meta name=DC.citation.epage content=192><meta name=DC.issued content=2024><meta name=DC.date content=2024><meta name=DC.format content=application/pdf><meta name=DC.identifier content=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf><meta name=DC.description content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><meta name=twitter:site content=https://wufeng02.github.io/doc/htm/QMWijcai24.html><meta property=twitter:title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta property=twitter:description content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><meta property=og:site_name content=https://wufeng02.github.io/doc/htm/QMWijcai24.html><meta property=og:title content="Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control"><meta property=og:url content=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf><meta property=og:description content="Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods."><link rel=canonical href=https://wufeng02.github.io/doc/htm/QMWijcai24.html><link rel=alternate hreflang=x-default href=https://wufeng02.github.io/doc/htm/QMWijcai24.html><link rel=alternate hreflang=en href="https://wufeng02.github.io/doc/htm/QMWijcai24.html?lang=en"><link rel=alternate hreflang=zh href="https://wufeng02.github.io/doc/htm/QMWijcai24.html?lang=zh"><link rel=search type=text/html href=https://wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=https://wufeng02.github.io/search.xml><link rel=icon href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=https://wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=https://wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=https://wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=https://wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_book_title itemprop=name>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)</span>, </span> Page <span itemprop=pagination>184-192</span>, <span class="citation_date citation_year" itemprop=datePublished>2024</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control </h1><h3 id=author class=citation_author><span itemprop=author> Yang Qu</span>, <span itemprop=author>Jinming Ma</span>, <span itemprop=author>Feng Wu </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>Active voltage control presents a promising avenue for relieving power congestion and enhancing voltage quality, taking advantage of the distributed controllable generators in the power network, such as roof-top photovoltaics. While Multi-Agent Reinforcement Learning (MARL) has emerged as a compelling approach to address this challenge, existing MARL approaches tend to overlook the constrained optimization nature of this problem, failing in guaranteeing safety constraints. In this paper, we formalize the active voltage control problem as a constrained Markov game and propose a safety-constrained MARL algorithm. We expand the primal-dual optimization RL method to multi-agent settings, and augment it with a novel approach of double safety estimation to learn the policy and to update the Lagrange-multiplier. In addition, we proposed different cost functions and investigated their influences on the behavior of our constrained MARL method. We evaluate our approach in the power distribution network simulation environment with real-world scale scenarios. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art MARL methods.</p> &raquo; <a href=https://wufeng02.github.io/doc/pdf/QMWijcai24.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 1011.2KB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Yang Qu</span>, <span class=cite_a>Jinming Ma</span>, <span class=cite_a>Feng Wu</span>. <span class=cite_t>Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control</span>. In <span class=cite_p>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)</span>, <span class=cite_s>pages 184-192</span>, <span class=cite_y>2024</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=https://wufeng02.github.io/doc/htm/QMWijcai24.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@inproceedings</span><span class=p>{</span><span class=nl>QMWijcai24</span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Yang Qu and Jinming Ma and Feng Wu<span class=p>}</span></span><span class=p>,</span>
 <span class=na>booktitle</span> <span class=p>=</span> <span class=s><span class=p>{</span>Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence (IJCAI)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>pages</span> <span class=p>=</span> <span class=s><span class=p>{</span>184-192<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2024<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Safety+Constrained+Multi-Agent+Reinforcement+Learning+for+Active+Voltage+Control" target=_blank>Google Scholar</a></li><li><a href="https://search.crossref.org/?q=Safety+Constrained+Multi-Agent+Reinforcement+Learning+for+Active+Voltage+Control" target=_blank>Crossref</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=https://wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>