<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=n/a><meta name=google-site-verification content=TlGo1hAtAmt_Rcaql8ze8OrWwroTFpl2bfmPzbysQkY><title>Feng Wu (吴锋) | Multi-Agent Patrolling under Uncertainty and Threats</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta name=citation_author content="Shaofei Chen"><meta name=citation_author content="Feng Wu"><meta name=citation_author content="Lincheng Shen"><meta name=citation_author content="Jing Chen"><meta name=citation_author content="Sarvapali D. Ramchurn"><meta name=citation_journal_title content="Public Library of Science"><meta name=citation_journal_abbrev content="PLOS ONE"><meta name=citation_volume content=10(6)><meta name=citation_firstpage content=e0130154><meta name=citation_lastpage content><meta name=citation_publication_date content=2015><meta name=citation_online_date content=2015><meta name=citation_date content=2015><meta name=citation_year content=2015><meta name=citation_doi content=10.1371/journal.pone.0130154><meta name=citation_pdf_url content=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf><meta name=citation_abstract content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><meta name=bepress_citation_title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta name=bepress_citation_author content="Shaofei Chen"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_author content="Lincheng Shen"><meta name=bepress_citation_author content="Jing Chen"><meta name=bepress_citation_author content="Sarvapali D. Ramchurn"><meta name=bepress_citation_journal_title content="Public Library of Science (PLOS ONE)"><meta name=bepress_citation_volume content=10(6)><meta name=bepress_citation_firstpage content=e0130154><meta name=bepress_citation_lastpage content><meta name=bepress_citation_date content=2015><meta name=bepress_citation_online_date content=2015><meta name=bepress_citation_doi content=10.1371/journal.pone.0130154><meta name=bepress_citation_pdf_url content=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf><meta name=bepress_citation_abstract_html_url content=//wufeng02.github.io/doc/htm/CWSplosone15.html><meta name=bepress_citation_abstract content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><meta name=eprints.source content=//wufeng02.github.io/doc/htm/CWSplosone15.html><meta name=eprints.title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta name=eprints.creators_name content="Shaofei Chen"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.creators_name content="Lincheng Shen"><meta name=eprints.creators_name content="Jing Chen"><meta name=eprints.creators_name content="Sarvapali D. Ramchurn"><meta name=eprints.type content=article><meta name=eprints.publication content="Public Library of Science (PLOS ONE)"><meta name=eprints.volume content=10(6)><meta name=eprints.date content=2015><meta name=eprints.date_type content=published><meta name=eprints.document_url content=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf><meta name=eprints.citation content="Shaofei Chen, Feng Wu, Lincheng Shen, Jing Chen, Sarvapali D. Ramchurn. Multi-Agent Patrolling under Uncertainty and Threats. Public Library of Science (PLOS ONE), 10(6):e0130154, 2015."><meta name=eprints.abstract content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=//wufeng02.github.io/doc/htm/CWSplosone15.html><meta name=DC.title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta name=DC.creator content="Shaofei Chen"><meta name=DC.creator content="Feng Wu"><meta name=DC.creator content="Lincheng Shen"><meta name=DC.creator content="Jing Chen"><meta name=DC.creator content="Sarvapali D. Ramchurn"><meta name=DC.type content=Article><meta name=DC.relation.ispartof content="Public Library of Science (PLOS ONE)"><meta name=DC.citation.volume content=10(6)><meta name=DC.citation.spage content=e0130154><meta name=DC.citation.epage content><meta name=DC.issued content=2015><meta name=DC.date content=2015><meta name=DC.format content=application/pdf><meta name=DC.identifier content=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf><meta name=DC.description content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><meta name=twitter:site content=//wufeng02.github.io/doc/htm/CWSplosone15.html><meta property=twitter:title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta property=twitter:description content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><meta property=og:site_name content=//wufeng02.github.io/doc/htm/CWSplosone15.html><meta property=og:title content="Multi-Agent Patrolling under Uncertainty and Threats"><meta property=og:url content=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf><meta property=og:description content="We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains."><link rel=canonical href=//wufeng02.github.io/doc/htm/CWSplosone15.html><link rel=alternate hreflang=x-default href=//wufeng02.github.io/doc/htm/CWSplosone15.html><link rel=alternate hreflang=en href="//wufeng02.github.io/doc/htm/CWSplosone15.html?lang=en"><link rel=alternate hreflang=zh href="//wufeng02.github.io/doc/htm/CWSplosone15.html?lang=zh"><link rel=search type=text/html href=//wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=//wufeng02.github.io/search.xml><link rel=icon href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=//wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=//wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=//wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=//wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_journal_title itemprop=name>Public Library of Science (PLOS ONE)</span>, </span><span itemprop=isPartOf itemscope itemtype=http://schema.org/PublicationVolume> Volume <span class=citation_volume itemprop=volumeNumber>10(6)</span>, </span> Page <span itemprop=pagination>e0130154</span>, <span class="citation_date citation_year" itemprop=datePublished>2015</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Multi-Agent Patrolling under Uncertainty and Threats </h1><h3 id=author class=citation_author><span itemprop=author> Shaofei Chen</span>, <span itemprop=author>Feng Wu</span>, <span itemprop=author>Lincheng Shen</span>, <span itemprop=author>Jing Chen</span>, <span itemprop=author>Sarvapali D. Ramchurn </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains.</p> &raquo; <a href=//wufeng02.github.io/doc/pdf/CWSplosone15.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 1.3MB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Shaofei Chen</span>, <span class=cite_a>Feng Wu</span>, <span class=cite_a>Lincheng Shen</span>, <span class=cite_a>Jing Chen</span>, <span class=cite_a>Sarvapali D. Ramchurn</span>. <span class=cite_t>Multi-Agent Patrolling under Uncertainty and Threats</span>. <span class=cite_p>Public Library of Science (PLOS ONE)</span>, <span class=cite_v>10(6)</span>:<span class=cite_s>e0130154</span>, <span class=cite_y>2015</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=//wufeng02.github.io/doc/htm/CWSplosone15.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@article</span><span class=p>{</span><span class=nl>CWSplosone15</span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D. Ramchurn<span class=p>}</span></span><span class=p>,</span>
 <span class=na>doi</span> <span class=p>=</span> <span class=s><span class=p>{</span>10.1371/journal.pone.0130154<span class=p>}</span></span><span class=p>,</span>
 <span class=na>journal</span> <span class=p>=</span> <span class=s><span class=p>{</span>Public Library of Science (PLOS ONE)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>pages</span> <span class=p>=</span> <span class=s><span class=p>{</span>e0130154<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Multi-Agent Patrolling under Uncertainty and Threats<span class=p>}</span></span><span class=p>,</span>
 <span class=na>volume</span> <span class=p>=</span> <span class=s><span class=p>{</span>10(6)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2015<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Multi-Agent+Patrolling+under+Uncertainty+and+Threats" target=_blank>Google Scholar</a> &mdash; Cited by <a href="https://scholar.google.com/scholar?oi=bibs&hl=ja&cites=14393036844054095698,13938201168227681777" target=_blank>13</a></li><li><a href="https://search.crossref.org/?q=Multi-Agent+Patrolling+under+Uncertainty+and+Threats" target=_blank>Crossref</a> &mdash; DOI: <a href=https://doi.org/10.1371/journal.pone.0130154 target=_blank class=citation_doi>10.1371/journal.pone.0130154</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a> &mdash; Accession Number: WOS:000356567500081 </li></ul></div><br></div><footer class=text-center><script type=text/javascript src=//wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=//wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=//wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>