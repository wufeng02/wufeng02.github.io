<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=7662302B2EE2DF855D33DA34FD827164><meta name=google-site-verification content=Nj_dp8eZCY7mCHa7wHJz4MXpILpTh7vii2xAujBW5Zg><title>Feng Wu (吴锋) | Stochastic Multi-Agent Planning with Partial State Models</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Stochastic Multi-Agent Planning with Partial State Models"><meta name=citation_author content="Feng Wu"><meta name=citation_author content="Shlomo Zilberstein"><meta name=citation_author content="Nicholas R. Jennings"><meta name=citation_book_title content="Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=citation_inbook_title content="Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=citation_conference_title content="The 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=citation_conference content="The 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=citation_firstpage content=1><meta name=citation_lastpage content=8><meta name=citation_publication_date content=2019><meta name=citation_online_date content=2019><meta name=citation_date content=2019><meta name=citation_year content=2019><meta name=citation_doi content=10.1145/3356464.3357699><meta name=citation_pdf_url content=//wufeng02.github.io/doc/pdf/WZJdai19.pdf><meta name=citation_abstract content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><meta name=bepress_citation_title content="Stochastic Multi-Agent Planning with Partial State Models"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_author content="Shlomo Zilberstein"><meta name=bepress_citation_author content="Nicholas R. Jennings"><meta name=bepress_citation_book_title content="Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=bepress_citation_firstpage content=1><meta name=bepress_citation_lastpage content=8><meta name=bepress_citation_date content=2019><meta name=bepress_citation_online_date content=2019><meta name=bepress_citation_doi content=10.1145/3356464.3357699><meta name=bepress_citation_pdf_url content=//wufeng02.github.io/doc/pdf/WZJdai19.pdf><meta name=bepress_citation_abstract_html_url content=//wufeng02.github.io/doc/htm/WZJdai19.html><meta name=bepress_citation_abstract content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><meta name=eprints.source content=//wufeng02.github.io/doc/htm/WZJdai19.html><meta name=eprints.title content="Stochastic Multi-Agent Planning with Partial State Models"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.creators_name content="Shlomo Zilberstein"><meta name=eprints.creators_name content="Nicholas R. Jennings"><meta name=eprints.type content=conference_item><meta name=eprints.event_type content=conference><meta name=eprints.event_title content="Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=eprints.date content=2019><meta name=eprints.date_type content=published><meta name=eprints.document_url content=//wufeng02.github.io/doc/pdf/WZJdai19.pdf><meta name=eprints.citation content="Feng Wu, Shlomo Zilberstein, Nicholas R. Jennings. Stochastic Multi-Agent Planning with Partial State Models. In Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI), pages 1-8, Beijing, China, October 2019."><meta name=eprints.abstract content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=//wufeng02.github.io/doc/htm/WZJdai19.html><meta name=DC.title content="Stochastic Multi-Agent Planning with Partial State Models"><meta name=DC.creator content="Feng Wu"><meta name=DC.creator content="Shlomo Zilberstein"><meta name=DC.creator content="Nicholas R. Jennings"><meta name=DC.type content="Conference or Workshop Item"><meta name=DC.relation.ispartof content="Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)"><meta name=DC.citation.spage content=1><meta name=DC.citation.epage content=8><meta name=DC.issued content=2019><meta name=DC.date content=2019><meta name=DC.format content=application/pdf><meta name=DC.identifier content=//wufeng02.github.io/doc/pdf/WZJdai19.pdf><meta name=DC.description content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><meta name=twitter:site content=//wufeng02.github.io/doc/htm/WZJdai19.html><meta property=twitter:title content="Stochastic Multi-Agent Planning with Partial State Models"><meta property=twitter:description content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><meta property=og:site_name content=//wufeng02.github.io/doc/htm/WZJdai19.html><meta property=og:title content="Stochastic Multi-Agent Planning with Partial State Models"><meta property=og:url content=//wufeng02.github.io/doc/pdf/WZJdai19.pdf><meta property=og:description content="People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches."><link rel=canonical href=//wufeng02.github.io/doc/htm/WZJdai19.html><link rel=alternate hreflang=x-default href=//wufeng02.github.io/doc/htm/WZJdai19.html><link rel=alternate hreflang=en href="//wufeng02.github.io/doc/htm/WZJdai19.html?lang=en"><link rel=alternate hreflang=zh href="//wufeng02.github.io/doc/htm/WZJdai19.html?lang=zh"><link rel=search type=text/html href=//wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=//wufeng02.github.io/search.xml><link rel=icon href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=//wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=//wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=//wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=//wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=//wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=//wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_book_title itemprop=name>Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)</span>, </span> Page <span itemprop=pagination>1-8</span>, <span class="citation_date citation_year" itemprop=datePublished>2019</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Stochastic Multi-Agent Planning with Partial State Models </h1><h3 id=author class=citation_author><span itemprop=author> Feng Wu</span>, <span itemprop=author>Shlomo Zilberstein</span>, <span itemprop=author>Nicholas R. Jennings </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>People who observe a multi-agent team can often provide valuable information to the agents based on their superior cognitive abilities to interpret sequences of observations and assess the overall situation. The knowledge they possess is often difficult to be fully represent using a formal model such as DEC-POMDP. To deal with this, we propose an extension of the DEC-POMDP that allows states to be partially specified and benefit from expert knowledge, while preserving the partial observability and decentralized operation of the agents. In particular, we present an algorithm for computing policies based on history samples that include human labeled data in the form of reward reshaping. We also consider ways to minimize the burden on human experts during the labeling phase. The results offer the first approach to incorporating human knowledge in such complex multi-agent settings. We demonstrate the benefits of our approach using a disaster recovery scenario, comparing it to several baseline approaches.</p> &raquo; <a href=//wufeng02.github.io/doc/pdf/WZJdai19.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 502.3KB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Feng Wu</span>, <span class=cite_a>Shlomo Zilberstein</span>, <span class=cite_a>Nicholas R. Jennings</span>. <span class=cite_t>Stochastic Multi-Agent Planning with Partial State Models</span>. In <span class=cite_p>Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)</span>, <span class=cite_s>pages 1-8</span>, <span class=cite_l>Beijing, China,</span> <span class=cite_m>October </span><span class=cite_y>2019</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=//wufeng02.github.io/doc/htm/WZJdai19.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@inproceedings</span><span class=p>{</span><span class=nl>WZJdai19</span><span class=p>,</span>
 <span class=na>address</span> <span class=p>=</span> <span class=s><span class=p>{</span>Beijing, China<span class=p>}</span></span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Feng Wu and Shlomo Zilberstein and Nicholas R. Jennings<span class=p>}</span></span><span class=p>,</span>
 <span class=na>booktitle</span> <span class=p>=</span> <span class=s><span class=p>{</span>Proceedings of the 1st International Conference on Distributed Artificial Intelligence (DAI)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>doi</span> <span class=p>=</span> <span class=s><span class=p>{</span>10.1145/3356464.3357699<span class=p>}</span></span><span class=p>,</span>
 <span class=na>month</span> <span class=p>=</span> <span class=s><span class=p>{</span>October<span class=p>}</span></span><span class=p>,</span>
 <span class=na>pages</span> <span class=p>=</span> <span class=s><span class=p>{</span>1-8<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Stochastic Multi-Agent Planning with Partial State Models<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2019<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Stochastic+Multi-Agent+Planning+with+Partial+State+Models" target=_blank>Google Scholar</a></li><li><a href="https://search.crossref.org/?q=Stochastic+Multi-Agent+Planning+with+Partial+State+Models" target=_blank>Crossref</a> &mdash; DOI: <a href=https://doi.org/10.1145/3356464.3357699 target=_blank class=citation_doi>10.1145/3356464.3357699</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=//wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=//wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=//wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>