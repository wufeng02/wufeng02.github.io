<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=n/a><meta name=google-site-verification content=TlGo1hAtAmt_Rcaql8ze8OrWwroTFpl2bfmPzbysQkY><title>Feng Wu (吴锋) | Multimodal Reinforcement Learning with Effective State Representation Learning</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta name=citation_author content="Jinming Ma"><meta name=citation_author content="Yingfeng Chen"><meta name=citation_author content="Feng Wu"><meta name=citation_author content="Xianpeng Ji"><meta name=citation_author content="Yu Ding"><meta name=citation_book_title content="Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=citation_inbook_title content="Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=citation_conference_title content="The 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=citation_conference content="The 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=citation_firstpage content=1684><meta name=citation_lastpage content=1686><meta name=citation_publication_date content=2022><meta name=citation_online_date content=2022><meta name=citation_date content=2022><meta name=citation_year content=2022><meta name=citation_pdf_url content=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf><meta name=citation_abstract content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><meta name=bepress_citation_title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta name=bepress_citation_author content="Jinming Ma"><meta name=bepress_citation_author content="Yingfeng Chen"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_author content="Xianpeng Ji"><meta name=bepress_citation_author content="Yu Ding"><meta name=bepress_citation_book_title content="Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=bepress_citation_firstpage content=1684><meta name=bepress_citation_lastpage content=1686><meta name=bepress_citation_date content=2022><meta name=bepress_citation_online_date content=2022><meta name=bepress_citation_pdf_url content=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf><meta name=bepress_citation_abstract_html_url content=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><meta name=bepress_citation_abstract content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><meta name=eprints.source content=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><meta name=eprints.title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta name=eprints.creators_name content="Jinming Ma"><meta name=eprints.creators_name content="Yingfeng Chen"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.creators_name content="Xianpeng Ji"><meta name=eprints.creators_name content="Yu Ding"><meta name=eprints.type content=conference_item><meta name=eprints.event_type content=conference><meta name=eprints.event_title content="Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=eprints.date content=2022><meta name=eprints.date_type content=published><meta name=eprints.document_url content=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf><meta name=eprints.citation content="Jinming Ma, Yingfeng Chen, Feng Wu, Xianpeng Ji, Yu Ding. Multimodal Reinforcement Learning with Effective State Representation Learning. In Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pages 1684-1686, Online, May 2022."><meta name=eprints.abstract content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><meta name=DC.title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta name=DC.creator content="Jinming Ma"><meta name=DC.creator content="Yingfeng Chen"><meta name=DC.creator content="Feng Wu"><meta name=DC.creator content="Xianpeng Ji"><meta name=DC.creator content="Yu Ding"><meta name=DC.type content="Conference or Workshop Item"><meta name=DC.relation.ispartof content="Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"><meta name=DC.citation.spage content=1684><meta name=DC.citation.epage content=1686><meta name=DC.issued content=2022><meta name=DC.date content=2022><meta name=DC.format content=application/pdf><meta name=DC.identifier content=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf><meta name=DC.description content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><meta name=twitter:site content=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><meta property=twitter:title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta property=twitter:description content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><meta property=og:site_name content=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><meta property=og:title content="Multimodal Reinforcement Learning with Effective State Representation Learning"><meta property=og:url content=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf><meta property=og:description content="Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality."><link rel=canonical href=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><link rel=alternate hreflang=x-default href=https://wufeng02.github.io/doc/htm/MCWJDaamas22.html><link rel=alternate hreflang=en href="https://wufeng02.github.io/doc/htm/MCWJDaamas22.html?lang=en"><link rel=alternate hreflang=zh href="https://wufeng02.github.io/doc/htm/MCWJDaamas22.html?lang=zh"><link rel=search type=text/html href=https://wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=https://wufeng02.github.io/search.xml><link rel=icon href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=https://wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=https://wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=https://wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=https://wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_book_title itemprop=name>Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</span>, </span> Page <span itemprop=pagination>1684-1686</span>, <span class="citation_date citation_year" itemprop=datePublished>2022</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Multimodal Reinforcement Learning with Effective State Representation Learning </h1><h3 id=author class=citation_author><span itemprop=author> Jinming Ma</span>, <span itemprop=author>Yingfeng Chen</span>, <span itemprop=author>Feng Wu</span>, <span itemprop=author>Xianpeng Ji</span>, <span itemprop=author>Yu Ding </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>Many real-world applications require an agent to make robust and deliberate decisions with multimodal information (eg, robots with multi-sensory inputs). However, it is very challenging to train the agent via reinforcement learning (RL) due to the heterogeneity and dynamic importance of different modalities. Specifically, we observe that these issues make conventional RL methods difficult to learn a useful state representation in the end-to-end training with multimodal information. To address this, we propose a novel multimodal RL approach that can do multimodal alignment and importance enhancement according to their similarity and importance in terms of RL tasks respectively. By doing so, we are able to learn an effective state representation and consequentially improve the RL training process. We test our approach on several multimodal RL domains, showing that it outperforms state-of-the-art methods in terms of learning speed and policy quality.</p> &raquo; <a href=https://wufeng02.github.io/doc/pdf/MCWJDaamas22.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 1.6MB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Jinming Ma</span>, <span class=cite_a>Yingfeng Chen</span>, <span class=cite_a>Feng Wu</span>, <span class=cite_a>Xianpeng Ji</span>, <span class=cite_a>Yu Ding</span>. <span class=cite_t>Multimodal Reinforcement Learning with Effective State Representation Learning</span>. In <span class=cite_p>Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)</span>, <span class=cite_s>pages 1684-1686</span>, <span class=cite_l>Online,</span> <span class=cite_m>May </span><span class=cite_y>2022</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=https://wufeng02.github.io/doc/htm/MCWJDaamas22.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@inproceedings</span><span class=p>{</span><span class=nl>MCWJDaamas22</span><span class=p>,</span>
 <span class=na>address</span> <span class=p>=</span> <span class=s><span class=p>{</span>Online<span class=p>}</span></span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Jinming Ma and Yingfeng Chen and Feng Wu and Xianpeng Ji and Yu Ding<span class=p>}</span></span><span class=p>,</span>
 <span class=na>booktitle</span> <span class=p>=</span> <span class=s><span class=p>{</span>Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>month</span> <span class=p>=</span> <span class=s><span class=p>{</span>May<span class=p>}</span></span><span class=p>,</span>
 <span class=na>pages</span> <span class=p>=</span> <span class=s><span class=p>{</span>1684-1686<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Multimodal Reinforcement Learning with Effective State Representation Learning<span class=p>}</span></span><span class=p>,</span>
 <span class=na>url</span> <span class=p>=</span> <span class=s><span class=p>{</span>https://dl.acm.org/doi/10.5555/3535850.3536076<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2022<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Multimodal+Reinforcement+Learning+with+Effective+State+Representation+Learning" target=_blank>Google Scholar</a></li><li><a href="https://search.crossref.org/?q=Multimodal+Reinforcement+Learning+with+Effective+State+Representation+Learning" target=_blank>Crossref</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=https://wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>