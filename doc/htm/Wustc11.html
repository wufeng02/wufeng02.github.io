<!DOCTYPE html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1"><meta name=robots content=NOODP,NOYDIR><meta name=msvalidate.01 content=n/a><meta name=google-site-verification content=TlGo1hAtAmt_Rcaql8ze8OrWwroTFpl2bfmPzbysQkY><title>Feng Wu (吴锋) | Decision-Theoretic Planning for Multi-Agent Systems</title><meta name=gs_meta_revision content=1.1><meta name=citation_title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta name=citation_author content="Feng Wu"><meta name=citation_dissertation_institution content="University of Science and Technology of China (USTC)"><meta name=citation_publication_date content=2011><meta name=citation_online_date content=2011><meta name=citation_date content=2011><meta name=citation_year content=2011><meta name=citation_doi content=10.7666/d.d141397><meta name=citation_pdf_url content=https://wufeng02.github.io/doc/pdf/Wustc11.pdf><meta name=citation_abstract content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><meta name=bepress_citation_title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta name=bepress_citation_author content="Feng Wu"><meta name=bepress_citation_dissertation_institution content="University of Science and Technology of China (USTC)"><meta name=bepress_citation_date content=2011><meta name=bepress_citation_online_date content=2011><meta name=bepress_citation_doi content=10.7666/d.d141397><meta name=bepress_citation_pdf_url content=https://wufeng02.github.io/doc/pdf/Wustc11.pdf><meta name=bepress_citation_abstract_html_url content=https://wufeng02.github.io/doc/htm/Wustc11.html><meta name=bepress_citation_abstract content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><meta name=eprints.source content=https://wufeng02.github.io/doc/htm/Wustc11.html><meta name=eprints.title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta name=eprints.creators_name content="Feng Wu"><meta name=eprints.type content=thesis><meta name=eprints.publisher content="University of Science and Technology of China (USTC)"><meta name=eprints.institution content="University of Science and Technology of China (USTC)"><meta name=eprints.date content=2011><meta name=eprints.date_type content=published><meta name=eprints.document_url content=https://wufeng02.github.io/doc/pdf/Wustc11.pdf><meta name=eprints.citation content="Feng Wu. Decision-Theoretic Planning for Multi-Agent Systems. University of Science and Technology of China (USTC), Hefei, China, July 2011."><meta name=eprints.abstract content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><link href=http://purl.org/dc/elements/1.1/ rel=schema.DC><meta name=DC.relation content=https://wufeng02.github.io/doc/htm/Wustc11.html><meta name=DC.title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta name=DC.creator content="Feng Wu"><meta name=DC.type content=Thesis><meta name=DC.publisher content="University of Science and Technology of China (USTC)"><meta name=DC.issued content=2011><meta name=DC.date content=2011><meta name=DC.format content=application/pdf><meta name=DC.identifier content=https://wufeng02.github.io/doc/pdf/Wustc11.pdf><meta name=DC.description content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><meta name=twitter:site content=https://wufeng02.github.io/doc/htm/Wustc11.html><meta property=twitter:title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta property=twitter:description content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><meta property=og:site_name content=https://wufeng02.github.io/doc/htm/Wustc11.html><meta property=og:title content="Decision-Theoretic Planning for Multi-Agent Systems"><meta property=og:url content=https://wufeng02.github.io/doc/pdf/Wustc11.pdf><meta property=og:description content="Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small " toy&quot; problems. as a nature extension of markov decision theory to multi-agent systems, the dec-pomdp model has very high computational complexity, namely nexp-hard. this is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. as a result, the joint policy space can be huge. hence how to search over the large joint policy space and find the best one is a key challenge when solving a large dec-pomdp. due to the problem complexity, exact algorithms can solve merely tiny problems. therefore, my thesis work focuses on developing effect algorithms for solving general dec-pomdps approximately. generally, planning in multi-agent systems can work either in online or offline fashions. this thesis contributes to the literature by proposing both online and offline algorithms. furthermore, a model-free algorithm is presented for planning when the exact model is not available.&quot;><link rel=canonical href=https://wufeng02.github.io/doc/htm/Wustc11.html><link rel=alternate hreflang=x-default href=https://wufeng02.github.io/doc/htm/Wustc11.html><link rel=alternate hreflang=en href="https://wufeng02.github.io/doc/htm/Wustc11.html?lang=en"><link rel=alternate hreflang=zh href="https://wufeng02.github.io/doc/htm/Wustc11.html?lang=zh"><link rel=search type=text/html href=https://wufeng02.github.io/search.html><link rel=search type=application/opensearchdescription+xml href=https://wufeng02.github.io/search.xml><link rel=icon href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel="shortcut icon" href=https://wufeng02.github.io/media/favicon.ico type=image/x-icon><link rel=stylesheet href=https://wufeng02.github.io/static/bootstrap/css/bootstrap.min.css type=text/css><script src=https://wufeng02.github.io/static/jquery/jquery.min.js type=text/javascript></script><script src=https://wufeng02.github.io/static/bootstrap/js/bootstrap.min.js type=text/javascript></script><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/base.min.css type=text/css><link rel=stylesheet href=https://wufeng02.github.io/static/pages/css/paper.css type=text/css><!--[if lt IE 9]>
      	<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      	<script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    	<![endif]--></head><body><br><div class=container itemscope itemtype=http://schema.org/ScholarlyArticle><ol class=breadcrumb><li style="width: auto; vertical-align: top;"><a href=https://wufeng02.github.io/publication.html><span itemprop=about>Publication</span></a></li><li class=active style="width: 90%;"><span itemprop=isPartOf itemscope itemtype=http://schema.org/Periodical><span class=citation_dissertation_institution itemprop=name>University of Science and Technology of China (USTC)</span>, </span> PhD Thesis, <span class="citation_date citation_year" itemprop=datePublished>2011</span>. </li></ol><h1 id=title class=citation_title itemprop="name headline"> Decision-Theoretic Planning for Multi-Agent Systems </h1><h3 id=author class=citation_author><span itemprop=author> Feng Wu </span></h3><h4 class="page-header clickable" data-toggle=collapse data-target=#abstract>Abstract</h4><p id=abstract class="citation_abstract collapse in" itemprop=description>Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small "toy" problems. As a nature extension of Markov decision theory to multi-agent systems, the DEC-POMDP model has very high computational complexity, namely NEXP-hard. This is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. As a result, the joint policy space can be huge. Hence how to search over the large joint policy space and find the best one is a key challenge when solving a large DEC-POMDP. Due to the problem complexity, exact algorithms can solve merely tiny problems. Therefore, my thesis work focuses on developing effect algorithms for solving general DEC-POMDPs approximately. Generally, planning in multi-agent systems can work either in online or offline fashions. This thesis contributes to the literature by proposing both online and offline algorithms. Furthermore, a model-free algorithm is presented for planning when the exact model is not available.</p> &raquo; <a href=https://wufeng02.github.io/doc/pdf/Wustc11.pdf class=citation_pdf_url itemprop="sameAs image" data-toggle=tooltip data-placement=right title="File Type: PDF, File Size: 1.8MB"> Read on </a><h4 class="page-header clickable" data-toggle=collapse data-target=#citation>Citation</h4><div id=citation class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=short class="btn btn-default btn-sm"><i class="glyphicon glyphicon-compressed"></i> Convert to short form </button></div><span><span class=cite_a>Feng Wu</span>. <span class=cite_t>Decision-Theoretic Planning for Multi-Agent Systems</span>. <span class=cite_p>University of Science and Technology of China (USTC)</span>, <span class=cite_l>Hefei, China,</span> <span class=cite_m>July </span><span class=cite_y>2011</span>.</span></div><h4 class="page-header clickable" data-toggle=collapse data-target=#bibtex>BibTex</h4><div id=bibtex class="collapse in"><div style="text-align: right; margin-bottom: 10px"><button id=copy class="btn btn-default btn-sm"><i class="glyphicon glyphicon-list-alt"></i> Copy to clipboard </button><a id=save class="btn btn-default btn-sm" href=https://wufeng02.github.io/doc/htm/Wustc11.bib target=_blank><i class="glyphicon glyphicon-download-alt"></i> Save as file </a></div><div class=highlight><pre><span></span><span class=nc>@phdthesis</span><span class=p>{</span><span class=nl>Wustc11</span><span class=p>,</span>
 <span class=na>address</span> <span class=p>=</span> <span class=s><span class=p>{</span>Hefei, China<span class=p>}</span></span><span class=p>,</span>
 <span class=na>author</span> <span class=p>=</span> <span class=s><span class=p>{</span>Feng Wu<span class=p>}</span></span><span class=p>,</span>
 <span class=na>doi</span> <span class=p>=</span> <span class=s><span class=p>{</span>10.7666/d.d141397<span class=p>}</span></span><span class=p>,</span>
 <span class=na>month</span> <span class=p>=</span> <span class=s><span class=p>{</span>July<span class=p>}</span></span><span class=p>,</span>
 <span class=na>school</span> <span class=p>=</span> <span class=s><span class=p>{</span>University of Science and Technology of China (USTC)<span class=p>}</span></span><span class=p>,</span>
 <span class=na>title</span> <span class=p>=</span> <span class=s><span class=p>{</span>Decision-Theoretic Planning for Multi-Agent Systems<span class=p>}</span></span><span class=p>,</span>
 <span class=na>year</span> <span class=p>=</span> <span class=s><span class=p>{</span>2011<span class=p>}</span></span>
<span class=p>}</span>
</pre></div></div><h4 class="page-header clickable" data-toggle=collapse data-target=#links>External Links</h4><div id=links class="collapse in"><ul><li><a href="https://scholar.google.com/scholar?q=Decision-Theoretic+Planning+for+Multi-Agent+Systems" target=_blank>Google Scholar</a> &mdash; Cited by <a href="https://scholar.google.com/scholar?oi=bibs&hl=ja&cites=11425927832966093044" target=_blank>4</a></li><li><a href="https://search.crossref.org/?q=Decision-Theoretic+Planning+for+Multi-Agent+Systems" target=_blank>Crossref</a> &mdash; DOI: <a href=https://doi.org/10.7666/d.d141397 target=_blank class=citation_doi>10.7666/d.d141397</a></li><li><a href=https://www.engineeringvillage.com/search/quick.url target=_blank>Engineering Village</a></li><li><a href=http://www.webofknowledge.com/wos target=_blank>Web of Science</a></li></ul></div><br></div><footer class=text-center><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/email.js></script><noscript><img src=https://wufeng02.github.io/img/email.png alt=Email></noscript></footer><br><script type=text/javascript src=https://wufeng02.github.io/static/pages/js/paper.min.js></script></body></html>