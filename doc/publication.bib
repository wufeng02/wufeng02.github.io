% Encoding: UTF-8

@Article{CWSijars17,
  author =   {Yingfeng Chen and Feng Wu and Wei Shuai and Xiaoping Chen},
  title =    {Robots serve humans in public places - {KeJia} robot as a shopping assistant},
  journal =  {International Journal of Advanced Robotic Systems (IJARS)},
  year =     {2017},
  volume =   {14},
  number =   {3},
  pages =    {1-20},
  abstract = {This paper reports the project of a shopping mall service robot, named KeJia, which is designed for customer guidance, providing information and entertainments in a real shopping mall environment. The background, motivations, and requirements of this project are analyzed and presented, which guide the development of the robot system. To develop the robot system, new techniques and improvements of existing methods for mapping, localization, and navigation are proposed to address the challenge of robot motion in a very large, complex, and crowded environment. Moreover, a novel multimodal interaction mechanism is designed by which customers can conveniently interact with the robot either in speech or via a mobile application. The KeJia robot was deployed in a large modern shopping mall with the size of 30,000 m2 and more than 160 shops; field trials were conducted for 40 days where about 530 customers were served. The results of both simulated experiments and field tests confirm the feasibility, stability, and safety of the robot system.},
  doi =      {10.1177/1729881417703569}
}

@InProceedings{LZWijcai17,
  author =    {Dongcai Lu and Yi Zhou and Feng Wu and Zhao Zhang and Xiaoping Chen},
  title =     {Integrating Answer Set Programming with Semantic Dictionaries for Robot Task Planning},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  year =      {2017},
  pages =     {4361-4367},
  address =   {Melbourne, Australia},
  month =     {August},
  abstract =  {In this paper, we propose a novel integrated task planning system for service robots in domestic domains. Given open-ended high-level user instructions in natural language, robots need to generate a plan, i.e., a sequence of low-level executable actions, to complete the required tasks. To address this, we exploit the knowledge on semantic roles of common verbs defined in semantic dictionaries such as FrameNet and integrate it with Answer Set Programming — a task planning framework with both representation language and solvers. In the experiments, we evaluated our approach using common benchmarks on service tasks and showed that it can successfully handle much more tasks than the state-of-the-art solution. Notably, we deployed the proposed planning system on our service robot for the annual RoboCup@Home competitions and achieved very encouraging results.},
  doi =       {10.24963/ijcai.2017/609}
}

@InProceedings{WWLrobocup17,
  author =    {Xiping Wang and Feng Wu and Dongcai Lu and Xiaoping Chen},
  title =     {A Robust Algorithm: Find an Unknown Person via Referring Grounding},
  booktitle = {Proceedings of the Robot World Cup XXI Symposium (RoboCup)},
  year =      {2017},
  address =   {Nagoya, Japan},
  month =     {July},
  abstract =  {We propose a simple but robust method to recognize an unknown person described in natural language. In this case, a robot is given a verbal description about a person whom the robot is required to recognize. This task is challenging since humans and robots have significantly mismatched perceptual capabilities (e.g., recognizing the color of a coat). Without assuming that all linguistic descriptions and perceptual data are correct, we use a probabilistic model to ground the target person. In particular, the acceptability of color descriptions is modeled based on visual similarity and the confusion matrix of the color classi- fier which make the system more robust to illumination. Two groups of experiments were conducted. Our experimental results demonstrate that our system is robust to both perception and description errors.}
}

@InProceedings{WZCijcai17,
  author =    {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title =     {Multi-Agent Planning with Baseline Regret Minimization},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  year =      {2017},
  pages =     {444-450},
  address =   {Melbourne, Australia},
  month =     {August},
  abstract =  {We propose a novel baseline regret minimization algorithm for multi-agent planning problems modeled as finite-horizon decentralized POMDPs. It guarantees to produce a policy that is provably at least as good as a given baseline policy. We also propose an iterative belief generation algorithm to efficiently minimize the baseline regret, which only requires necessary iterations so as to converge to the policy with minimum baseline regret. Experimental results on common benchmark problems confirm the benefits of the algorithm compared with the state-of-the-art approaches.},
  doi =       {10.24963/ijcai.2017/63}
}

@InProceedings{ZCZicira17,
  author =    {Haochong Zhang and Rongyun Cao and Shlomo Zilberstein and Feng Wu and Xiaoping Chen},
  title =     {Toward Effective Soft Robot Control via Reinforcement Learning},
  booktitle = {Proceedings of the 10th International Conference on Intelligent Robotics and Applications (ICIRA)},
  year =      {2017},
  pages =     {173-184},
  address =   {Wuhan, China},
  month =     {August},
  abstract =  {A soft robot is a kind of robot that is constructed with soft, deformable and elastic materials. Control of soft robots presents complex modeling and planning challenges. We introduce a new approach to accomplish that, making two key contributions: designing an abstract representation of the state of soft robots, and developing a reinforcement learning method to derive effective control policies. The reinforcement learning process can be trained quickly by ignoring the specific materials and structural properties of the soft robot. We apply the approach to the Honeycomb PneuNets Soft Robot and demonstrate the effectiveness of the training method and its ability to produce good control policies under different conditions.},
  doi =       {10.1007/978-3-319-65289-4_17}
}

@InProceedings{ZCCicira17,
  author =    {Kuisong Zheng and Guangda Chen and Guowei Cui and Yingfeng Chen and Feng Wu and Xiaoping Chen},
  title =     {Performance Metrics for Coverage of Cleaning Robots with {MoCap} System},
  booktitle = {Proceedings of the 10th International Conference on Intelligent Robotics and Applications (ICIRA)},
  year =      {2017},
  pages =     {267-274},
  address =   {Wuhan, China},
  month =     {August},
  abstract =  {Nowadays there are a lot of kinds of cleaning robots which producted by different manufacturers come into people’s lives. But it is still a problem that how to evaluate each robot’s performance to check whether the quality is acceptable. In this paper, we make the first trial to evaluate the complete coverage path planning algorithm which is the core algorithm of a cleaning robot with Mocap system, and three simple metrics were proposed to evaluate overall performance of the algorithm. Lastly, the comparisons between different kinds of robots are presented.},
  doi =       {10.1007/978-3-319-65298-6_25}
}

@InProceedings{ZCWicira17,
  author =    {Kuisong Zheng and Yingfeng Chen and Feng Wu and Xiaoping Chen},
  title =     {A General Batch-Calibration Framework of Service Robots},
  booktitle = {Proceedings of the 10th International Conference on Intelligent Robotics and Applications (ICIRA)},
  year =      {2017},
  pages =     {275-286},
  address =   {Wuhan, China},
  month =     {August},
  abstract =  {Calibration is important to service robot, but the process of calibration is time consuming and laborious. With the popularity of service robot, an automatic and universal calibration system is urgent to be developed, therefore we propose a general batch-calibration framework, Motion Capture System is adopt as an external measurement device in virtual of it can provide realtime, accurate movement data of measured objects. We will show that the system is effective and promising with a case study of odometry calibration.},
  doi =       {10.1007/978-3-319-65298-6_26}
}

@Article{FGJccpe16,
  author =   {Joel E. Fischer and Chris Greenhalgh and Wenchao Jiang and Sarvapali D. Ramchurn and Feng Wu and Tom Rodden},
  title =    {In-the-loop or on-the-loop? Interactional arrangements to support team coordination with a planning agent},
  journal =  {Concurrency and Computation: Practice and Experience (CCPE)},
  year =     {2016},
  pages =    {e4082},
  abstract = {In this paper we present the study of interactional arrangements that support the collaboration of headquarters (HQ), field responders and a computational planning agent in a time-critical task setting created by a mixed-reality game. Interactional arrangements define the extent to which control is distributed between the collaborative parties. We provide two field trials, one to study an “on-the-loop” arrangement in which HQ monitors and intervenes in agent instructions to field players on demand, and the other to study a version that places headquarters more tightly “in-the-loop”. The studies provide and understanding of the sociotechnical collaboration between players and the agent in these interactional arrangements, by conducting interaction analysis of video recordings and game log data. The first field trial focuses on the collaboration of field responders with the planning agent. Findings highlight how players negotiate the agent guidance within the social interaction of the collocated teams. The second field trial focuses on the collaboration between the automated planning agent and the headquarters. We find that the human coordinator and the agent can successfully work together in most cases, with human coordinators inspecting and ‘correcting’     the agent-proposed plans. Through this field trial-driven development process, we generalise interaction design implications of automated planning agents around the themes of supporting common ground and mixed-initiative planning.},
  doi =      {10.1002/cpe.4082}
}

@Article{RHWjair16,
  author =   {Sarvapali D. Ramchurn and Trung Dong Huynh and Feng Wu and Yuki Ikuno and Jack Flann and Luc Moreau and Joel E. Fischer and Wenchao Jiang and Tom Rodden and Edwin Simpson and Steven Reece and Stephen Roberts and Nicholas R. Jennings},
  title =    {A Disaster Response System based on Human-Agent Collectives},
  journal =  {Journal of Artificial Intelligence Research (JAIR)},
  year =     {2016},
  volume =   {57},
  pages =    {661-708},
  abstract = {Major natural or man-made disasters such as Hurricane Katrina or the 9/11 terror attacks pose significant challenges for emergency responders. First, they have to develop an understanding of the unfolding event either using their own resources or through third-parties such as the local population and agencies. Second, based on the information gathered, they need to deploy their teams in a flexible manner, ensuring that each team performs tasks in the most effective way. Third, given the dynamic nature of a disaster space, and the uncertainties involved in performing rescue missions, information about the disaster space and the actors within it needs to be managed to ensure that responders are always acting on up-to-date and trusted information. Against this background, this paper proposes a novel disaster response system called HAC-ER. Thus HAC-ER interweaves humans and agents, both robotic and software, in social relationships that augment their individual and collective capabilities. To design HAC-ER, we involved end-users including both experts and volunteers in a several participatory design workshops, lab studies, and field trials of increasingly advanced prototypes of individual components of HAC-ER as well as the overall system. This process generated a number of new quantitative and qualitative results but also raised a number of new research questions. HAC-ER thus demonstrates how such Human-Agent Collectives (HACs) can address key challenges in disaster response. Specifically, we show how HAC-ER utilises crowdsourcing combined with machine learning to obtain most important situational awareness from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments, as well as task planning for responders on the ground. Finally, HAC-ER incorporates an infrastructure and the associated intelligence for tracking and utilising the provenance of information shared across the entire system to ensure its accountability. We individually validate each of these elements of HAC-ER and show how they perform against standard (non-HAC) baselines and also elaborate on the evaluation of the overall system.},
  doi =      {10.1613/jair.5098}
}

@InProceedings{WRCijcai16,
  author =    {Feng Wu and Sarvapali D. Ramchurn and Xiaoping Chen},
  title =     {Coordinating Human-{UAV} Teams in Disaster Response},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  year =      {2016},
  pages =     {524-530},
  address =   {New York, USA},
  month =     {July},
  abstract =  {We consider a disaster response scenario where emergency responders have to complete rescue tasks in dynamic and uncertain environment with the assistance of multiple UAVs to collect information about the disaster space. To capture the uncertainty and partial observability of the domain, we model this problem as a POMDP. However, the resulting model is computationally intractable and cannot be solved by most existing POMDP solvers due to the large state and action spaces. By exploiting the problem structure we propose a novel online planning algorithm to solve this model. Specifically, we generate plans for the responders based on Monte-Carlo simulations and compute actions for the UAVs according to the value of information. Our empirical results confirm that our algorithm significantly outperforms the state-of-the-art both in time and solution quality.}
}

@Article{BWCtist15,
  author =   {Aijun Bai and Feng Wu and Xiaoping Chen},
  title =    {Online Planning for Large Markov Decision Processes with Hierarchical Decomposition},
  journal =  {ACM Transactions on Intelligent Systems and Technology (ACM TIST)},
  year =     {2015},
  volume =   {6(4)},
  number =   {45},
  month =    {August},
  abstract = {Markov decision processes (MDPs) provide a rich framework for planning under uncertainty. However, exactly solving a large MDP is usually intractable due to the ''curse of dimensionality'' - the state space grows exponentially with the number of state variables. Online algorithms tackle this problem by avoiding computing a policy for the entire state space. On the other hand, since online algorithm has to find a near-optimal action online in almost real time, the computation time is often very limited. In the context of reinforcement learning, MAXQ is a value function decomposition method that exploits the underlying structure of the original MDP and decomposes it into a combination of smaller subproblems arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in online settings. Compared to traditional online planning algorithms, MAXQ-OP is able to reach much more deeper states in the search tree with relatively less computation time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the effectiveness of our approach. We have also conducted a long-term case study in a highly complex simulated soccer domain and developed a team named WrightEagle that has won five world champions and five runners-up in the recent 10 years of RoboCup Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm the scalability of MAXQ-OP to very large domains.},
  doi =      {10.1145/2717316}
}

@Article{CWSieee15,
  author =   {Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D. Ramchurn},
  title =    {Decentralized Patrolling Under Constraints in Dynamic Environments},
  journal =  {IEEE Transactions on Cybernetics (IEEE SMC)},
  year =     {2015},
  volume =   {46},
  number =   {12},
  pages =    {3364-3376},
  abstract = {We investigate a decentralized patrolling problem for dynamic environments where information is distributed alongside threats. In this problem, agents obtain information at a location, but may suffer attacks from the threat at that location. In a decentralized fashion, each agent patrols in a designated area of the environment and interacts with a limited number of agents. Therefore, the goal of these agents is to coordinate to gather as much information as possible while limiting the damage incurred. Hence, we model this class of problem as a transition-decoupled partially observable Markov decision process with health con- straints. Furthermore, we propose scalable decentralized online algorithms based on Monte Carlo tree search and a factored belief vector. We empirically evaluate our algorithms on decen- tralized patrolling problems and benchmark them against the state-of-the-art online planning solver. The results show that our approach outperforms the state-of-the-art by more than 56% for six agents patrolling problems and can scale up to 24 agents in reasonable time.},
  doi =      {10.1109/TCYB.2015.2505737}
}

@Article{CWSplosone15,
  author =   {Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D. Ramchurn},
  title =    {Multi-Agent Patrolling under Uncertainty and Threats},
  journal =  {Public Library of Science (PLOS ONE)},
  year =     {2015},
  volume =   {10(6)},
  pages =    {e0130154},
  abstract = {We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) 	and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains.},
  doi =      {10.1371/journal.pone.0130154}
}

@InProceedings{CWSicsr15,
  author =    {Yingfeng Chen and Feng Wu and Wei Shuai and Ningyang Wang and Rongya Chen and Xiaoping Chen},
  title =     {KeJia Robot - an Attractive Shopping Mall Guider},
  booktitle = {Proceedings of the 7th International Conference on Social Robotics (ICSR)},
  year =      {2015},
  pages =     {145-154},
  address =   {Paris, France},
  month =     {October},
  abstract =  {This paper reports the project of a shopping mall guide robot, named KeJia, which is designed for customer navigation, informa- tion providing and entertainment in a real environment. Our introduction focuses on the designs of robot's hardware and software, faced challenges and the multimodal interaction methods including using a mobile phone app. In order to adapt the current localization and navigation techniques to such large and complex shopping mall environment, a series of related improvements and new methods are proposed. The robot is deployed in a large shopping mall for field test and stable operation for a fairly long time. The result demonstrates the stability, validity and feasibility of this robot system, and gives a positive reward to our original design motivation.},
  doi =       {10.1007/978-3-319-25554-5_15}
}

@InProceedings{CWWrobocup15,
  author =    {Yingfeng Chen and Feng Wu and Ningyang Wang and Keke Tang and Min Cheng and Xiaoping Chen},
  title =     {KeJia-LC: A Low-Cost Mobile Robot Platform - Champion of Demo Challenge on Benchmarking Service Robots at RoboCup 2015.},
  booktitle = {Proceedings of the Robot World Cup XIX Symposium (RoboCup)},
  year =      {2015},
  volume =    {9513},
  pages =     {60-71},
  address =   {Hefei, China},
  month =     {July},
  abstract =  {In this paper, we present the system design and the key techniques of our mobile robot platform called KeJia-LC, who won the first place in the demo challenge on Benchmarkinng Service Robots in RoboCup 2015. Given the fact that KeJia-LC is a low-cost version of our KeJia robot without shoulder and arm, several new technical demands comparing to RoboCup@Home are highlighted for better understanding of our system. With the elaborate design of hardware and the reasonable selection of sensors, our robot platform has the features of low cost, wide generality and good extensibility. Moreover, we integrate several functional softwares (such as 2D&3D mapping, localization and navigation) 	following the competition rules, which are critical to the performance of our robot. The effectiveness and robustness of our robot system has been proven in the competition.},
  doi =       {10.1007/978-3-319-29339-4_5}
}

@InProceedings{CCTrobocup15,
  author =    {Min Cheng and Xiaoping Chen and Keke Tang and Feng Wu and Andras Kupcsik and Luca Iocchi and Yingfeng Chen and David Hsu},
  title =     {Synthetical Benchmarking of Service Robots: A First Effort on Domestic Mobile Platforms},
  booktitle = {Proceedings of the Robot World Cup XIX Symposium (RoboCup)},
  year =      {2015},
  volume =    {9513},
  pages =     {377-388},
  address =   {Hefei, China},
  month =     {July},
  abstract =  {Most of existing benchmarking tools for service robots are basically qualitative, in which a robot's performance on a task is evaluated based on completion/incompletion of actions contained in the task. In the effort reported in this paper, we tried to implement a synthetical benchmarking system on domestic mobile platforms. Synthetical benchmarking consists of both qualitative and quantitative aspects, such as task completion, accuracy of task completions and efficiency of task completions, about performance of a robot. The system includes a set of algorithms for collecting, recording and analyzing measurement data from a MoCap system. It was used as the evaluator in a competition called the BSR challenge, in which 10 teams participated, at RoboCup 2015. The paper presents our motivations behind synthetical benchmarking, the design considerations on the synthetical benchmarking system, the realization of the competition as a comparative study on performance evaluation of domestic mobile platforms, and an analysis of the teams' 	performance.},
  doi =       {10.1007/978-3-319-29339-4_32}
}

@INPROCEEDINGS{RFIijcai15,
  author = {Sarvapali D. Ramchurn and Joel E. Fischer and Yuki Ikuno and Feng Wu and Jack Flann and Antony Waldock},
  title = {A Study of Human-Agent Collaboration for Multi-UAV Task Allocation in Dynamic Environments},
  booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2015},
  pages = {1184-1192},
  address = {Buenos Aires, Argentina},
  month = {July},
  abstract = {We consider a setting where a team of humans oversee the coordination of multiple Unmanned Aerial Vehicles (UAVs) to perform a number of search tasks in dynamic environments that may cause the UAVs to drop out. Hence, we develop a set of multi-UAV supervisory control interfaces and a multi-agent coordination algorithm to support human decision making in this setting. To elucidate the resulting interactional issues, we compare manual and mixed-initiative task allocation in both static and dynamic environments in lab studies with 40 participants and observe that our mixed-initiative system results in lower workloads and better performance in re-planning tasks than one which only involves manual task allocation. Our analysis points to new insights into the way humans appropriate flexible autonomy.}
}

@InProceedings{RHIaamas15,
  author =    {Sarvapali D. Ramchurn and Trung Dong Huynh and Yuki Ikuno and Jack Flann and Feng Wu and Luc Moreau and Nicholas R. Jennings and Joel E. Fischer and Wenchao Jiang and Tom Rodden and Edwin Simpson and Steven Reece and Stephen Roberts},
  title =     {HAC-ER: A Disaster Response System based on Human-Agent Collectives},
  booktitle = {Proceedings of the 14th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},
  year =      {2015},
  pages =     {533-541},
  address =   {Istanbul, Turkey},
  month =     {May},
  note =      {Best Paper Award (Applications Track)},
  abstract =  {This paper proposes a novel disaster management system called HAC-ER that addresses some of the challenges faced by emergency responders by enabling humans and agents, using state-of-the-art algorithms, to collaboratively plan and carry out tasks in teams referred to as human-agent collectives. In particular, HAC-ER utilises crowdsourcing combined with machine learning to extract situational awareness information from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments as well as task planning for responders on the ground. Finally, HAC-ER incorporates a tool for tracking and analysing the provenance of information shared across the entire system. In summary, this paper describes a prototype system, validated by real-world emergency responders, that combines several state-of-the-art techniques for integrating humans and agents,
	and illustrates, for the first time, how such an approach can enable more effective disaster response operations.}
}

@Article{RWFjaamas15,
  author =   {Sarvapali D. Ramchurn and Feng Wu and Joel E. Fischer and Steven Reece and Wenchao Jiang and Stephen Roberts and Tom Rodden and Chris Greenhalgh and Nicholas R. Jennings},
  title =    {Human-Agent Collaboration for Disaster Response},
  journal =  {Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS)},
  year =     {2015},
  volume =   {30},
  number =   {1},
  pages =    {82-111},
  abstract = {In the aftermath of major disasters, first responders are typically overwhelmed with large numbers of, spatially distributed, search and rescue tasks, each with their own requirements. Moreover, responders have to operate in highly uncertain and dynamic environments where new tasks may appear and hazards may be spreading across the disaster space. Hence, rescue missions may need to be re-planned as new information comes in, tasks are completed, or new hazards are discovered. Finding an optimal allocation of resources to complete all the tasks is a major computational challenge. In this paper, we use decision theoretic techniques to solve the task allocation problem posed by emergency response planning and then deploy our solution as part of an agent-based planning tool in real-world field trials. By so doing, we are able to study the interactional issues that arise when humans are guided by an agent. Specifically, we develop an algorithm, based on a Multi-Agent Markov Decision Process representation of the task allocation problem and show that it outperforms standard baseline solutions. We then integrate the algorithm into a planning agent that responds to requests for tasks from participants in a mixed-reality location-based game, called AtomicOrchid, that simulates disaster response settings in the real-world. We then run a number of trials of our planning agent and compare it against a purely human driven system. Our analysis of these trials show that human commanders adapt to the planning agent by taking on a more supervisory role and that, by providing humans with the flexibility of requesting plans from the agent, allows them to perform more tasks more efficiently than using purely human interactions to allocate tasks. We also discuss how such flexibility could lead to poor performance if left unchecked.},
  doi =      {10.1007/s10458-015-9286-4}
}

@InProceedings{WRJijcai15,
  author =    {Feng Wu and Sarvapali D. Ramchurn and Wenchao Jiang and Joel E. Fischer and Tom Rodden and Nicholas R. Jennings},
  title =     {Agile Planning for Real-World Disaster Response},
  booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  year =      {2015},
  pages =     {132-138},
  address =   {Buenos Aires, Argentina},
  month =     {July},
  note =      {Selected for Press Conference (4/575)},
  abstract =  {We consider a setting where an agent-based planner instructs teams of human emergency responders to perform tasks in the real world. Due to uncertainty in the environment and the inability of the planner to consider all human preferences and all attributes of the real-world, humans may reject plans computed by the agent. A naıve solution that replans given a rejection is inefficient and does not guarantee the new plan will be acceptable. Hence, we propose a new model re-planning problem using a Multi-agent Markov Decision Process that integrates potential rejections as part of the planning process and propose a novel algorithm to effi- ciently solve this new model. We empirically evaluate our algorithm and show that it outperforms current benchmarks. Our algorithm is also shown to perform better in pilot studies with real humans.}
}

@INPROCEEDINGS{BWZicaps14,
  author = {Aijun Bai and Feng Wu and Zongzhang Zhang and Xiaoping Chen},
  title = {Thompson Sampling based Monte-Carlo Planning in {POMDPs}},
  booktitle = {Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)},
  year = {2014},
  pages = {29-37},
  address = {Portsmouth, United States},
  abstract = {Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) 	treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems.}
}

@InProceedings{JFGcts14,
  author =    {Wenchao Jiang and Joel E. Fischer and Chris Greenhalgh and Sarvapali D. Ramchurn and Feng Wu and Nicholas R. Jennings and Tom Rodden},
  title =     {Social Implications of Agent-based Planning Support for Human Teams},
  booktitle = {Proceedings of the 2014 International Conference on Collaboration Technologies and Systems (CTS)},
  year =      {2014},
  pages =     {310-317},
  address =   {Minneapolis, United States},
  month =     {May},
  abstract =  {We present a field trial of how instructions from an intelligent planning agent are dealt with by distributed human teams, in a time-critical task setting created through a mixed-reality game. We conduct interaction analysis to examine video recorded field observations and game log data. The findings highlight the social process by which players interpret and negotiate the agent guidance as well as how these are intertwined with social dynamics of the teams. The insights can be used to develop an understanding of interactional issues around automated team instructions and inform the design of human-centred planning support systems.},
  doi =       {10.1109/CTS.2014.6867582}
}

@InProceedings{SWJaamas14,
  author =    {Sarvapali D. Ramchurn and Feng Wu and Wenchao Jiang and Joel E. Fischer and Steven Reece and Chris Greenhalgh and Tom Rodden and Nicholas R. Jennings and Stephen Roberts},
  title =     {{AtomicOrchid}: Human-Agent Collectives to the Rescue},
  booktitle = {Proceedings of the 13th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},
  year =      {2014},
  pages =     {1693-1694},
  address =   {Paris, France}
}

@INPROCEEDINGS{WJaaai14,
  author = {Feng Wu and Nicholas R. Jennings},
  title = {Regret-Based Multi-Agent Coordination with Uncertain Task Rewards},
  booktitle = {Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI)},
  year = {2014},
  pages = {1492-1499},
  address = {Quebec City, Canada},
  abstract = {Many multi-agent coordination problems can be represented as DCOPs. Motivated by task allocation in disaster response, we extend standard DCOP models to consider uncertain task rewards where the outcome of completing a task depends onits current state, which is randomly drawn from unknown distributions. The goal of solving this problem is to find a solution for all agents that minimizes the overall worst-case loss. This is a challenging problem for centralized algorithms because the search space grows exponentially with the number of agents and is nontrivial for existing algorithms for standard DCOPs. To address this, we propose a novel decentralized algorithm that incorporates Max-Sum with iterative constraint generation to solve the problem by passing messages among agents. By so doing, our approach scales well and can solve instances of the task allocation problem with hundreds of agents and tasks.}
}

@INPROCEEDINGS{BWCnips13,
  author = {Aijun Bai and Feng Wu and Xiaoping Chen},
  title = {Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search},
  booktitle = {Proceedings of the Advances in Neural Information Processing Systems (NIPS)},
  year = {2013},
  pages = {1646-1654},
  address = {Lake Tahoe, United States},
  abstract = {Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning and learning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we present a novel approach for MCTS using Bayesian mixture modeling and inference based Thompson sampling and apply it to the problem of online planning in MDPs. Our algorithm, named Dirichlet-NormalGamma MCTS (DNG-MCTS), models the uncertainty of the accumulated reward for actions in the search tree as a mixture of Normal distributions. We perform inferences on the mixture in Bayesian settings by choosing conjugate priors in the form of combinations of Dirichlet and NormalGamma distributions and select the best action at each decision node using Thompson sampling. Experimental results confirm that our algorithm advances the state-of-the-art UCT approach with better values on several benchmark problems.}
}

@INPROCEEDINGS{WZJijcai13,
  author = {Feng Wu and Shlomo Zilberstein and Nicholas R. Jennings},
  title = {Monte-Carlo Expectation Maximization for Decentralized {POMDPs}},
  booktitle = {Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2013},
  pages = {397-403},
  address = {Beijing, China},
  abstract = {We address two significant drawbacks of state-of-the-art solvers of decentralized POMDPs (DEC-POMDPs): the reliance on complete knowledge of the model and limited scalability as the complexity of the domain grows. We extend a recently proposed approach for solving DEC-POMDPs via a reduction to the maximum likelihood problem, which in turn can be solved using EM. We introduce a model-free version of this approach that employs Monte-Carlo EM (MCEM). While a naive implementation of MCEM is inadequate in multiagent settings, we introduce several improvements in sampling that produce high-quality results on a variety of DEC-POMDP benchmarks, including large problems with thousands of agents.}
}

@InProceedings{BWCaamas12,
  author =    {Aijun Bai and Feng Wu and Xiaoping Chen},
  title =     {Online Planning for Large {MDPs} with {MAXQ}-like Decomposition},
  booktitle = {Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  year =      {2012},
  pages =     {1215-1216},
  address =   {Valencia, Spain},
  abstract =  {Markov decision processes (MDPs) provide an expressive framework for planning in stochastic domains. However, exactly solving a large MDP is often intractable due to the curse of dimensionality. Online algorithms help overcome the high computational complexity by avoiding computing a policy for each possible state. Hierarchical decomposition is another promising way to help scale MDP algorithms up to large domains by exploiting their underlying structure. In this paper, we present an effort on combining the benefits of a general hierarchical structure based on MAXQ value function decomposition with the power of heuristic and approximate techniques for developing an online planning framework, called MAXQ-OP. The proposed framework provides a principled approach for programming autonomous agents in a large stochastic domain. We have been conducting a long-term case-study with the RoboCup soccer simulation 2D domain, which is extremely larger than domains usually studied in literature, as the major benchmark to this research. The case-study showed that the agents developed with this framework and the related techniques reached outstanding performances, showing its high scalability to very large domains.}
}

@InProceedings{BWCrobocup12,
  author =    {Aijun Bai and Feng Wu and Xiaoping Chen},
  title =     {Towards a Principled Solution to Simulated Robot Soccer},
  booktitle = {Proceedings of the Robot Soccer World Cup XVI Symposium (RoboCup)},
  year =      {2012},
  pages =     {141-153},
  address =   {Mexico City, Mexico},
  abstract =  {The RoboCup soccer simulation 2D domain is a very large testbed for the research of planning and machine learning. It has competed in the annual world championship tournaments in the past 15 years. However it is still unclear that whether more principled techniques such as decision-theoretic planning take an important role in the success for a RoboCup 2D team. In this paper, we present a novel approach based on MAXQ-OP to automated planning in the RoboCup 2D domain. It combines the benefits of a general hierarchical structure based on MAXQ value function decomposition with the power of heuristic and approximate techniques. The proposed framework provides a principled solution to programming autonomous agents in large stochastic domains. The MAXQ-OP framework has been implemented in our RoboCup 2D team, WrightEagle. The empirical results indicated that the agents developed with this framework and related techniques reached outstanding performances, showing its potential of scalability to very large domains.},
  doi =       {10.1007/978-3-642-39250-4_14}
}

@InProceedings{WJCecai12,
  author =    {Feng Wu and Nicholas R. Jennings and Xiaoping Chen},
  title =     {Sample-Based Policy Iteration for Constrained {DEC-POMDPs}},
  booktitle = {Proceedings of the 20th European Conference on Artificial Intelligence (ECAI)},
  year =      {2012},
  pages =     {858-863},
  address =   {Montpellier, France},
  abstract =  {We introduce constrained DEC-POMDPsCan extension of the standard DEC-POMDPs including additional constraints to the optimality of the long-term reward. Constrained DEC-POMDPs present natural framework for modeling cooperative multi-agent problems with limited resources or multiple objectives. To solve constrained DEC-POMDPs, we propose a novel sample-based policy iteration algorithm. The algorithm builds up on multi-agent dynamic programming and benefits from several advantages of recentdeveloped DEC-POMDP algorithms. It improves the joint policy by solving a serial of standard nonlinear programs and thereby lends itself the power of existing NLP solvers. The experimental results confirm that the algorithm can efficiently solve constrained DECPOMDPs while the general DEC-POMDP algorithms fail. It outperforms the leading DEC-POMDP method with higher value and less chance of constraint violation.},
  doi =       {10.3233/978-1-61499-098-7-858}
}

@PhdThesis{Wustc11,
  author =   {Feng Wu},
  title =    {Decision-Theoretic Planning for Multi-Agent Systems},
  school =   {University of Science and Technology of China (USTC)},
  year =     {2011},
  address =  {Hefei, China},
  month =    {July},
  note =     {In Chinese},
  abstract = {Planning under uncertainty is one of the fundamental challenges in Artificial Intelligence. Decision theory offers a mathematical framework for optimizing decisions in these domains. In recent years, researchers have made rapid progresses for decision making in single-agent cases. This enables relatively large problems to be solved by state-of-the-art MDP or POMDP algorithms. However, the research of decentralized decision making is still in its infancy and existing solutions can only solve very small “toy” problems. As a nature extension of Markov decision theory to multi-agent systems, the DEC-POMDP model has very high computational complexity, namely NEXP-hard. This is not surprising given that agents in multi-agent settings not only have to keep tracking on the state transition of the environment but also the potential behaviors of the other agents. As a result, the joint policy space can be huge. Hence how to search over the large joint policy space and find the best one is a key challenge when solving a large DEC-POMDP. Due to the problem complexity, exact algorithms can solve merely tiny problems. Therefore, my thesis work focuses on developing effect algorithms for solving general DEC-POMDPs approximately. Generally, planning in multi-agent systems can work either in online or offline fashions. This thesis contributes to the literature by proposing both online and offline algorithms. Furthermore,
a model-free algorithm is presented for planning when the exact model is not available.}
}

@InProceedings{WZCijcai11,
  author =    {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title =     {Online Planning for Ad Hoc Autonomous Agent Teams},
  booktitle = {Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI)},
  year =      {2011},
  pages =     {439-445},
  address =   {Barcelona, Spain},
  abstract =  {We propose a novel online planning algorithm for ad hoc team settings' 	challenging situations in which an agent must collaborate with unknown teammates without prior coordination. Our approach is based on constructing and solving a series of stage games, and then using biased adaptive play to choose actions. The utility function in each stage game is estimated via Monte-Carlo tree search using the UCT algorithm. We establish analytically the convergence of the algorithm and show that it performs well in a variety of ad hoc team domains.},
  doi =       {10.5591/978-1-57735-516-8/IJCAI11-081}
}

@Article{WZCaij11,
  author =   {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title =    {Online Planning for Multi-Agent Systems with Bounded Communication},
  journal =  {Artificial Intelligence (AIJ)},
  year =     {2011},
  volume =   {175},
  number =   {2},
  pages =    {487-511},
  abstract = {We propose an online algorithm for planning under uncertainty in multi-agent settings modeled as DEC-POMDPs. The algorithm helps overcome the high computational complexity of solving such problems offline. The key challenges in decentralized operation are to maintain coordinated behavior with little or no communication and, when communication is allowed, to optimize value with minimal communication. The algorithm addresses these challenges by generating identical conditional plans based on common knowledge and communicating only when history inconsistency is detected, allowing communication to be postponed when necessary. To be suitable for online operation, the algorithm computes good local policies using a new and fast local search method implemented using linear programming. Moreover, it bounds the amount of memory used at each step and can be applied to problems with arbitrary horizons. The experimental results confirm that the algorithm can solve problems that are too large for the best existing offline planning algorithms and it outperforms the best online method, producing much higher value with much less communication in most cases. The algorithm also proves to be effective when the communication channel is imperfect (periodically unavailable). These results contribute to the scalability of decision-theoretic planning in multi-agent settings.},
  doi =      {10.1016/j.artint.2010.09.008}
}

@INPROCEEDINGS{WZCaamas10,
  author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title = {Point-Based Policy Generation for Decentralized {POMDPs}},
  booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},
  year = {2010},
  pages = {1307-1314},
  address = {Toronto, Canada},
  abstract = {Memory-bounded techniques have shown great promise in solving complex multi-agent planning problems modeled as DEC-POMDPs. Much of the performance gains can be attributed to pruning techniques that alleviate the complexity of the exhaustive backup step of the original MBDP algorithm. Despite these improvements, state-of-the-art algorithms can still handle a relative small pool of candidate policies, which limits the quality of the solution in some benchmark problems. We present a new algorithm, Point- Based Policy Generation, which avoids altogether searching the entire joint policy space. The key observation is that the best joint policy for each reachable belief state can be constructed directly, instead of producing first a large set of candidates. We also provide an efficient approximate implementation of this operation. The experimental results show that our solution technique improves the performance significantly in terms of both runtime and solution quality.}
}

@INPROCEEDINGS{WZCuai10,
  author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title = {Rollout Sampling Policy Iteration for Decentralized {POMDPs}},
  booktitle = {Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI)},
  year = {2010},
  pages = {666-673},
  address = {Catalina, United States},
  abstract = {We present decentralized rollout sampling policy iteration (DecRSPI) -- a new algorithm for multiagent decision problems formalized as DECPOMDPs. DecRSPI is designed to improve scalability and tackle problems that lack an explicit model. The algorithm uses Monte-Carlo methods to generate a sample of reachable belief states. Then it computes a joint policy for each belief state based on the rollout estimations. A new policy representation allows us to represent solutions compactly. The key benefits of the algorithm are its linear time complexity over the number of agents, its bounded memory usage and good solution quality. It can solve larger problems that are intractable for existing planning algorithms. Experimental results confirm the effectiveness and scalability of the approach.}
}

@INPROCEEDINGS{WZCaaai10,
  author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title = {Trial-Based Dynamic Programming for Multi-Agent Planning},
  booktitle = {Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI)},
  year = {2010},
  pages = {908-914},
  address = {Atlanta, United States},
  abstract = {Trial-based approaches offer an efficient way to solve singleagent MDPs and POMDPs. These approaches allow agents to focus their computations on regions of the environment they encounter during the trials, leading to significant computational savings. We present a novel trial-based dynamic programming (TBDP) algorithm for DEC-POMDPs that extends these benefits to multi-agent settings. The algorithm uses trial-based methods for both belief generation and policy evaluation. Policy improvement is implemented efficiently using linear programming and a sub-policy reuse technique that helps bound the amount of memory. The results show that TBDP can produce significant value improvements and is much faster than the best existing planning algorithms.}
}

@INPROCEEDINGS{WZCicaps09,
  author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title = {Multi-Agent Online Planning with Communication},
  booktitle = {Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS)},
  year = {2009},
  pages = {321-329},
  address = {Thessaloniki, Greece},
  abstract = {We propose an online algorithm for planning under uncertainty in multi-agent settings modeled as DEC-POMDPs. The algorithm helps overcome the high computational complexity of solving such problems off-line. The key challenge is to produce coordinated behavior using little or no communication. When communication is allowed but constrained, the challenge is to produce high value with minimal communication. The algorithm addresses these challenges by communicating only when history inconsistency is detected, allowing communication to be postponed if necessary. Moreover, it bounds the memory usage at each step and can be applied to problems with arbitrary horizons. The experimental results confirm that the algorithm can solve problems that are too large for the best existing off-line planning algorithms and it outperforms the best online method, producing higher value with much less communication in most cases.}
}

@InProceedings{WCrobocup07,
  author =    {Feng Wu and Xiaoping Chen},
  title =     {Solving Large-Scale and Sparse-Reward {DEC-POMDPs} with Correlation-{MDPs}},
  booktitle = {Proceedings of the Robot Soccer World Cup XI Symposium (RoboCup)},
  year =      {2007},
  pages =     {208-219},
  address =   {Atlanta, United States},
  abstract =  {Within a group of cooperating agents the decision making of an individual agent depends on the actions of the other agents. A lot of effort has been made to solve this problem with additional assumptions on the communication abilities of agents. However, in some realworld applications, communication is limited and the assumptions are rarely satisfied. An alternative approach newly developed is to employ a correlation device to correlate the agents' behavior without exchanging information during execution. In this paper, we apply correlation device to large-scale and spare-reward domains. As a basis we use the framework of infinite-horizon DEC-POMDPs which represent policies as joint stochastic finite-state controllers. To solve any problem of this kind, a correlation device is firstly calculated by solving Correlation Markov Decision Processes (Correlation-MDPs) and then used to improve the local controller for each agent. By using this method, we are able to achieve a tradeoff between computational complexity and the quality of the approximation. In addition, we demonstrate that, adversarial problems can be solved by encoding the information of opponents'ddate behavior in the correlation device.We have successfully implemented the proposed method into our 2D simulated robot soccer team and the performance in RoboCup-2006 was encouraging.},
  doi =       {10.1007/978-3-540-68847-1_18}
}

@InProceedings{BFWrobocup05,
  author =    {Peng Bai and Changjie Fan and Feng Wu and Xiaoping Chen},
  title =     {WrightEagle 2D Simulation Team 2005},
  booktitle = {Proceedings of Robot Soccer World Cup IX Symposium (RoboCup)},
  year =      {2005},
  address =   {Osaka, Japan},
  month =     {July},
  abstract =  {This paper introduces the implementation of Wright Eagle 2-D Simulation team 2005. The team is implemented on the basis of WrightEagle 2004 and thus inherits the decision-making framework of its antecedent, which is a combination of a simplified model of MDP and PRS system. In WrightEagle2005, we re-build several key basic-action modules of the team in order to enhance the performance of the agent, such as the Unknown-player Matching algorithm, the new Fast-Dribble skill and the fixed Pass-Ball algorithm, and we also use a new decision-making structure which is based on POMDP method to implement the tactic behavior.}
}

@InProceedings{WZCaaai18,
  author    = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},
  title     = {Privacy-Preserving Policy Iteration for Decentralized POMDPs},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2018},
  address   = {New Orleans, USA},
  month     = {February},
  abstract  = {We propose the first privacy-preserving approach to address the privacy issues that arise in multi-agent planning problems modeled as a Dec-POMDP. Our solution is a distributed message-passing algorithm based on trials, where the agents’ policies are optimized using the cross-entropy method. In our algorithm, the agents’ private information is protected using a public-key homomorphic cryptosystem. We prove the correctness of our algorithm and analyze its complexity in terms of message passing and encryption/decryption operations. Furthermore, we analyze several privacy aspects of our algorithm and show that it can preserve the agent privacy of non-neighbors, model privacy, and decision privacy. Our experimental results on several common Dec-POMDP benchmark problems confirm the effectiveness of our approach.},
}

