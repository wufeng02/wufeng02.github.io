{"pages":[{"url":"//wufeng02.github.io/publication.html#BWCtist15","text":"Aijun Bai and Feng Wu and Xiaoping Chen, article, Markov decision processes (MDPs) provide a rich framework for planning under uncertainty. However, exactly solving a large MDP is usually intractable due to the ''curse of dimensionality'' - the state space grows exponentially with the number of state variables. Online algorithms tackle this problem by avoiding computing a policy for the entire state space. On the other hand, since online algorithm has to find a near-optimal action online in almost real time, the computation time is often very limited. In the context of reinforcement learning, MAXQ is a value function decomposition method that exploits the underlying structure of the original MDP and decomposes it into a combination of smaller subproblems arranged over a task hierarchy. In this article, we present MAXQ-OP—a novel online planning algorithm for large MDPs that utilizes MAXQ hierarchical decomposition in online settings. Compared to traditional online planning algorithms, MAXQ-OP is able to reach much more deeper states in the search tree with relatively less computation time by exploiting MAXQ hierarchical decomposition online. We empirically evaluate our algorithm in the standard Taxi domain—a common benchmark for MDPs—to show the effectiveness of our approach. We have also conducted a long-term case study in a highly complex simulated soccer domain and developed a team named WrightEagle that has won five world champions and five runners-up in the recent 10 years of RoboCup Soccer Simulation 2D annual competitions. The results in the RoboCup domain confirm the scalability of MAXQ-OP to very large domains., Online Planning for Large Markov Decision Processes with Hierarchical Decomposition, 45, August, 6(4), @article{BWCtist15,\n author = {Aijun Bai and Feng Wu and Xiaoping Chen},\n journal = {ACM Transactions on Intelligent Systems and Technology (ACM TIST)},\n month = {August},\n number = {45},\n title = {Online Planning for Large Markov Decision Processes with Hierarchical Decomposition},\n volume = {6(4)},\n year = {2015}\n}\n\n, 2015, doc/pdf/BWCtist15.pdf, BWCtist15, ACM Transactions on Intelligent Systems and Technology (ACM TIST)","tags":"publication","title":"Online Planning for Large Markov Decision Processes with Hierarchical Decomposition"},{"url":"//wufeng02.github.io/publication.html#CCTrobocup15","text":"Min Cheng and Xiaoping Chen and Keke Tang and Feng Wu and Andras Kupcsik and Luca Iocchi and Yingfeng Chen and David Hsu, Most of existing benchmarking tools for service robots are basically qualitative, in which a robot's performance on a task is evaluated based on completion/incompletion of actions contained in the task. In the effort reported in this paper, we tried to implement a synthetical benchmarking system on domestic mobile platforms. Synthetical bench- marking consists of both qualitative and quantitative aspects, such as task completion, accuracy of task completions and efficiency of task completions, about performance of a robot. The system includes a set of algorithms for collecting, recording and analyzing measurement data from a MoCap system. It was used as the evaluator in a competition called the BSR challenge, in which 10 teams participated, at RoboCup 2015. The paper presents our motivations behind synthetical benchmarking, the design considerations on the synthetical benchmarking system, the realization of the competition as a comparative study on performance evaluation of domestic mobile platforms, and an analysis of the teams' performance., Synthetical Benchmarking of Service Robots: A First Effort on Domestic Mobile Platforms, inproceedings, 9513, @inproceedings{CCTrobocup15,\n author = {Min Cheng and Xiaoping Chen and Keke Tang and Feng Wu and Andras Kupcsik and Luca Iocchi and Yingfeng Chen and David Hsu},\n booktitle = {Proceedings of the Robot World Cup XIX Symposium (RoboCup)},\n pages = {377-388},\n title = {Synthetical Benchmarking of Service Robots: A First Effort on Domestic Mobile Platforms},\n volume = {9513},\n year = {2015}\n}\n\n, 2015, doc/pdf/CCTrobocup15.pdf, CCTrobocup15, Proceedings of the Robot World Cup XIX Symposium (RoboCup), 377-388","tags":"publication","title":"Synthetical Benchmarking of Service Robots: A First Effort on Domestic Mobile Platforms"},{"url":"//wufeng02.github.io/publication.html#CWSicsr15","text":"KeJia Robot - an Attractive Shopping Mall Guider, This paper reports the project of a shopping mall guide robot, named KeJia, which is designed for customer navigation, informa- tion providing and entertainment in a real environment. Our introduction focuses on the designs of robot's hardware and software, faced challenges and the multimodal interaction methods including using a mobile phone app. In order to adapt the current localization and navigation techniques to such large and complex shopping mall environment, a series of related improvements and new methods are proposed. The robot is deployed in a large shopping mall for field test and stable operation for a fairly long time. The result demonstrates the stability, validity and feasibility of this robot system, and gives a positive reward to our original design motivation., Yingfeng Chen and Feng Wu and Wei Shuai and Ningyang Wang and Rongya Chen and Xiaoping Chen, inproceedings, @inproceedings{CWSicsr15,\n author = {Yingfeng Chen and Feng Wu and Wei Shuai and Ningyang Wang and Rongya Chen and Xiaoping Chen},\n booktitle = {Proceedings of the 7th International Conference on Social Robotics (ICSR)},\n pages = {145-154},\n title = {KeJia Robot - an Attractive Shopping Mall Guider},\n year = {2015}\n}\n\n, 2015, doc/pdf/CWSicsr15.pdf, CWSicsr15, Proceedings of the 7th International Conference on Social Robotics (ICSR), 145-154","tags":"publication","title":"KeJia Robot - an Attractive Shopping Mall Guider"},{"url":"//wufeng02.github.io/publication.html#CWSieee15","text":"Decentralized Patrolling Under Constraints in Dynamic Environments, IEEE Transactions on Cybernetics (IEEE SMC), Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D Ramchurn, We investigate a decentralized patrolling problem for dynamic environments where information is distributed alongside threats. In this problem, agents obtain information at a location, but may suffer attacks from the threat at that location. In a decentralized fashion, each agent patrols in a designated area of the environment and interacts with a limited number of agents. Therefore, the goal of these agents is to coordinate to gather as much information as possible while limiting the damage incurred. Hence, we model this class of problem as a transition-decoupled partially observable Markov decision process with health con- straints. Furthermore, we propose scalable decentralized online algorithms based on Monte Carlo tree search and a factored belief vector. We empirically evaluate our algorithms on decen- tralized patrolling problems and benchmark them against the state-of-the-art online planning solver. The results show that our approach outperforms the state-of-the-art by more than 56% for six agents patrolling problems and can scale up to 24 agents in reasonable time., article, @article{CWSieee15,\n author = {Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D Ramchurn},\n journal = {IEEE Transactions on Cybernetics (IEEE SMC)},\n pages = {1-13},\n title = {Decentralized Patrolling Under Constraints in Dynamic Environments},\n year = {2015}\n}\n\n, 2015, doc/pdf/CWSieee15.pdf, CWSieee15, 1-13","tags":"publication","title":"Decentralized Patrolling Under Constraints in Dynamic Environments"},{"url":"//wufeng02.github.io/publication.html#CWSplosone15","text":"Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D. Ramchurn, Public Library of Science (PLOS ONE), We investigate a multi-agent patrolling problem where information is distributed alongside threats in environments with uncertainties. Specifically, the information and threat at each location are independently modelled as multi-state Markov chains, whose states are not observed until the location is visited by an agent. While agents will obtain information at a location, they may also suffer damage from the threat at that location. Therefore, the goal of the agents is to gather as much information as possible while mitigating the damage incurred. To address this challenge, we formulate the single-agent patrolling problem as a Partially Observable Markov Decision Process (POMDP) and propose a computationally efficient algorithm to solve this model. Building upon this, to compute patrols for multiple agents, the single-agent algorithm is extended for each agent with the aim of maximising its marginal contribution to the team. We empirically evaluate our algorithm on problems of multi-agent patrolling and show that it outperforms a baseline algorithm up to 44% for 10 agents and by 21% for 15 agents in large domains., Multi-Agent Patrolling under Uncertainty and Threats, article, 10(6), @article{CWSplosone15,\n author = {Shaofei Chen and Feng Wu and Lincheng Shen and Jing Chen and Sarvapali D. Ramchurn},\n journal = {Public Library of Science (PLOS ONE)},\n pages = {e0130154},\n title = {Multi-Agent Patrolling under Uncertainty and Threats},\n volume = {10(6)},\n year = {2015}\n}\n\n, 2015, doc/pdf/CWSplosone15.pdf, CWSplosone15, e0130154","tags":"publication","title":"Multi-Agent Patrolling under Uncertainty and Threats"},{"url":"//wufeng02.github.io/publication.html#CWWrobocup15","text":"Yingfeng Chen and Feng Wu and Ningyang Wang and Keke Tang and Min Cheng and Xiaoping Chen, In this paper, we present the system design and the key techniques of our mobile robot platform called KeJia-LC, who won the first place in the demo challenge on Benchmarkinng Service Robots in RoboCup 2015. Given the fact that KeJia-LC is a low-cost version of our KeJia robot without shoulder and arm, several new technical demands comparing to RoboCup@Home are highlighted for better understanding of our system. With the elaborate design of hardware and the reasonable selection of sensors, our robot platform has the features of low cost, wide generality and good extensibility. Moreover, we integrate several functional softwares (such as 2D&3D mapping, localization and navigation) following the competition rules, which are critical to the performance of our robot. The effectiveness and robustness of our robot system has been proven in the competition., KeJia-LC: A Low-Cost Mobile Robot Platform - Champion of Demo Challenge on Benchmarking Service Robots at RoboCup 2015., inproceedings, 9513, @inproceedings{CWWrobocup15,\n author = {Yingfeng Chen and Feng Wu and Ningyang Wang and Keke Tang and Min Cheng and Xiaoping Chen},\n booktitle = {Proceedings of the Robot World Cup XIX Symposium (RoboCup)},\n pages = {60-71},\n title = {KeJia-LC: A Low-Cost Mobile Robot Platform - Champion of Demo Challenge on Benchmarking Service Robots at RoboCup 2015.},\n volume = {9513},\n year = {2015}\n}\n\n, 2015, doc/pdf/CWWrobocup15.pdf, CWWrobocup15, Proceedings of the Robot World Cup XIX Symposium (RoboCup), 60-71","tags":"publication","title":"KeJia-LC: A Low-Cost Mobile Robot Platform - Champion of Demo Challenge on Benchmarking Service Robots at RoboCup 2015."},{"url":"//wufeng02.github.io/publication.html#RFIijcai15","text":"Sarvapali D. Ramchurn and Joel E. Fischer and Yuki Ikuno and Feng Wu and Jack Flann and Antony Waldock, A Study of Human-Agent Collaboration for Multi-UAV Task Allocation in Dynamic Environments, inproceedings, We consider a setting where a team of humans oversee the coordination of multiple Unmanned Aerial Vehicles (UAVs) to perform a number of search tasks in dynamic environments that may cause the UAVs to drop out. Hence, we develop a set of multi-UAV supervisory control interfaces and a multi-agent coordination algorithm to support human decision making in this setting. To elucidate the resulting interactional issues, we compare manual and mixed-initiative task allocation in both static and dynamic environments in lab studies with 40 participants and observe that our mixed-initiative system results in lower workloads and better performance in re-planning tasks than one which only involves manual task allocation. Our analysis points to new insights into the way humans appropriate flexible autonomy., Buenos Aires, Argentina, July, @inproceedings{RFIijcai15,\n address = {Buenos Aires, Argentina},\n author = {Sarvapali D. Ramchurn and Joel E. Fischer and Yuki Ikuno and Feng Wu and Jack Flann and Antony Waldock},\n booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},\n month = {July},\n pages = {1184-1192},\n title = {A Study of Human-Agent Collaboration for Multi-UAV Task Allocation in Dynamic Environments},\n year = {2015}\n}\n\n, 1184-1192, 2015, doc/pdf/RFIijcai15.pdf, RFIijcai15, Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)","tags":"publication","title":"A Study of Human-Agent Collaboration for Multi-UAV Task Allocation in Dynamic Environments"},{"url":"//wufeng02.github.io/publication.html#RHIaamas15","text":"HAC-ER: A Disaster Response System based on Human-Agent Collectives, inproceedings, This paper proposes a novel disaster management system called HAC-ER that addresses some of the challenges faced by emergency responders by enabling humans and agents, using state-of-the-art algorithms, to collaboratively plan and carry out tasks in teams referred to as human-agent collectives. In particular, HAC-ER utilises crowdsourcing combined with machine learning to extract situational awareness information from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments as well as task planning for responders on the ground. Finally, HAC-ER incorporates a tool for tracking and analysing the provenance of information shared across the entire system. In summary, this paper describes a prototype system, validated by real-world emergency responders, that combines several state-of-the-art techniques for integrating humans and agents, and illustrates, for the first time, how such an approach can enable more effective disaster response operations., Sarvapali D. Ramchurn and Trung Dong Huynh and Yuki Ikuno and Jack Flann and Feng Wu and Luc Moreau and Nicholas R. Jennings and Joel Fischer and Wenchao Jiang and Tom Rodden and Edwin Simpson and Steven Reece and Stephen Roberts, May, Innovative Applications Track Best Paper (1/167), @inproceedings{RHIaamas15,\n address = {Istanbul, Turkey},\n author = {Sarvapali D. Ramchurn and Trung Dong Huynh and Yuki Ikuno and Jack Flann and Feng Wu and Luc Moreau and Nicholas R. Jennings and Joel Fischer and Wenchao Jiang and Tom Rodden and Edwin Simpson and Steven Reece and Stephen Roberts},\n booktitle = {Proceedings of the 14th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},\n month = {May},\n pages = {533-541},\n title = {HAC-ER: A Disaster Response System based on Human-Agent Collectives},\n year = {2015}\n}\n\n, 533-541, 2015, doc/pdf/RHIaamas15.pdf, RHIaamas15, Proceedings of the 14th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), Istanbul, Turkey","tags":"publication","title":"HAC-ER: A Disaster Response System based on Human-Agent Collectives"},{"url":"//wufeng02.github.io/publication.html#RWFjaamas15","text":"Human-Agent Collaboration for Disaster Response, Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS), Sarvapali D. Ramchurn and Feng Wu and Joel E. Fischer and Steven Reece and Wenchao Jiang and Stephen Roberts and Tom Rodden and Chris Greenhalgh and Nicholas R. Jennings, In the aftermath of major disasters, first responders are typically overwhelmed with large numbers of, spatially distributed, search and rescue tasks, each with their own requirements. Moreover, responders have to operate in highly uncertain and dynamic environments where new tasks may appear and hazards may be spreading across the disaster space. Hence, rescue missions may need to be re-planned as new information comes in, tasks are completed, or new hazards are discovered. Finding an optimal allocation of resources to complete all the tasks is a major computational challenge. In this paper, we use decision theoretic techniques to solve the task allocation problem posed by emergency response planning and then deploy our solution as part of an agent-based planning tool in real-world field trials. By so doing, we are able to study the interactional issues that arise when humans are guided by an agent. Specifically, we develop an algorithm, based on a Multi-Agent Markov Decision Process representation of the task allocation problem and show that it outperforms standard baseline solutions. We then integrate the algorithm into a planning agent that responds to requests for tasks from participants in a mixed-reality location-based game, called AtomicOrchid, that simulates disaster response settings in the real-world. We then run a number of trials of our planning agent and compare it against a purely human driven system. Our analysis of these trials show that human commanders adapt to the planning agent by taking on a more supervisory role and that, by providing humans with the flexibility of requesting plans from the agent, allows them to perform more tasks more efficiently than using purely human interactions to allocate tasks. We also discuss how such flexibility could lead to poor performance if left unchecked., article, @article{RWFjaamas15,\n author = {Sarvapali D. Ramchurn and Feng Wu and Joel E. Fischer and Steven Reece and Wenchao Jiang and Stephen Roberts and Tom Rodden and Chris Greenhalgh and Nicholas R. Jennings},\n journal = {Journal of Autonomous Agents and Multi-Agent Systems (JAAMAS)},\n pages = {1-30},\n title = {Human-Agent Collaboration for Disaster Response},\n year = {2015}\n}\n\n, 2015, doc/pdf/RWFjaamas15.pdf, RWFjaamas15, 1-30","tags":"publication","title":"Human-Agent Collaboration for Disaster Response"},{"url":"//wufeng02.github.io/publication.html#WRJijcai15","text":"Agile Planning for Real-World Disaster Response, inproceedings, We consider a setting where an agent-based planner instructs teams of human emergency responders to perform tasks in the real world. Due to uncertainty in the environment and the inability of the planner to consider all human preferences and all attributes of the real-world, humans may reject plans computed by the agent. A naıve solution that replans given a rejection is inefficient and does not guarantee the new plan will be acceptable. Hence, we propose a new model re-planning problem using a Multi-agent Markov Decision Process that integrates potential rejections as part of the planning process and propose a novel algorithm to effi- ciently solve this new model. We empirically evaluate our algorithm and show that it outperforms current benchmarks. Our algorithm is also shown to perform better in pilot studies with real humans., Feng Wu and Sarvapali D. Ramchurn and Wenchao Jiang and Jeol E. Fischer and Tom Rodden and Nicholas R. Jennings, July, Selected for Press Conference (4/575), @inproceedings{WRJijcai15,\n address = {Buenos Aires, Argentina},\n author = {Feng Wu and Sarvapali D. Ramchurn and Wenchao Jiang and Jeol E. Fischer and Tom Rodden and Nicholas R. Jennings},\n booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},\n month = {July},\n pages = {132-138},\n title = {Agile Planning for Real-World Disaster Response},\n year = {2015}\n}\n\n, 132-138, 2015, doc/pdf/WRJijcai15.pdf, WRJijcai15, Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI), Buenos Aires, Argentina","tags":"publication","title":"Agile Planning for Real-World Disaster Response"},{"url":"//wufeng02.github.io/publication.html#BWZicaps14","text":"Aijun Bai and Feng Wu and Zongzhang Zhang and Xiaoping Chen, Thompson Sampling based Monte-Carlo Planning in POMDPs, Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we introduce a novel online planning algorithm for large POMDPs using Thompson sampling based MCTS that balances between cumulative and simple regrets. The proposed algorithm Dirichlet-Dirichlet-Normal Gamma based Partially Observable Monte-Carlo Planning (D2NG-POMCP) treats the accumulated reward of performing an action from a belief state in the MCTS search tree as a random variable following an unknown distribution with hidden parameters. Bayesian method is used to model and infer the posterior distribution of these parameters by choosing the conjugate prior in the form of a combination of two Dirichlet and one NormalGamma distributions. Thompson sampling is exploited to guide the action selection in the search tree. Experimental results confirmed that our algorithm outperforms the state-of-the-art approaches on several common benchmark problems., Portsmouth, United States, inproceedings, @inproceedings{BWZicaps14,\n address = {Portsmouth, United States},\n author = {Aijun Bai and Feng Wu and Zongzhang Zhang and Xiaoping Chen},\n booktitle = {Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS)},\n pages = {29-37},\n title = {Thompson Sampling based Monte-Carlo Planning in {POMDPs}},\n year = {2014}\n}\n\n, 2014, doc/pdf/BWZicaps14.pdf, BWZicaps14, Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS), 29-37","tags":"publication","title":"Thompson Sampling based Monte-Carlo Planning in POMDPs"},{"url":"//wufeng02.github.io/publication.html#JFGcts14","text":"Wenchao Jiang and Joel E. Fischer and Chris Greenhalgh and Sarvapali D. Ramchurn and Feng Wu and Nicholas R. Jennings and Tom Rodden, Social Implications of Agent-based Planning Support for Human Teams, inproceedings, We present a field trial of how instructions from an intelligent planning agent are dealt with by distributed human teams, in a time-critical task setting created through a mixed-reality game. We conduct interaction analysis to examine video recorded field observations and game log data. The findings highlight the social process by which players interpret and negotiate the agent guidance as well as how these are intertwined with social dynamics of the teams. The insights can be used to develop an understanding of interactional issues around automated team instructions and inform the design of human-centred planning support systems., Minneapolis, United States, May, @inproceedings{JFGcts14,\n address = {Minneapolis, United States},\n author = {Wenchao Jiang and Joel E. Fischer and Chris Greenhalgh and Sarvapali D. Ramchurn and Feng Wu and Nicholas R. Jennings and Tom Rodden},\n booktitle = {Proceedings of the 2014 International Conference on Collaboration Technologies and Systems (CTS)},\n month = {May},\n pages = {310-317},\n title = {Social Implications of Agent-based Planning Support for Human Teams},\n year = {2014}\n}\n\n, 310-317, 2014, doc/pdf/JFGcts14.pdf, JFGcts14, Proceedings of the 2014 International Conference on Collaboration Technologies and Systems (CTS)","tags":"publication","title":"Social Implications of Agent-based Planning Support for Human Teams"},{"url":"//wufeng02.github.io/publication.html#SWJaamas14","text":"Sarvapali D. Ramchurn and Feng Wu and Wenchao Jiang and Joel E. Fischer and Steve Reece and Chris Greenhalgh and Tom Rodden and Nicholas R. Jennings and Stephen Roberts, AtomicOrchid: Human-Agent Collectives to the Rescue (Demostration), Proceedings of the 13th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), Paris, France, inproceedings, @inproceedings{SWJaamas14,\n address = {Paris, France},\n author = {Sarvapali D. Ramchurn and Feng Wu and Wenchao Jiang and Joel E. Fischer and Steve Reece and Chris Greenhalgh and Tom Rodden and Nicholas R. Jennings and Stephen Roberts},\n booktitle = {Proceedings of the 13th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},\n pages = {1693-1694},\n title = {{AtomicOrchid}: Human-Agent Collectives to the Rescue (Demostration)},\n year = {2014}\n}\n\n, 2014, doc/pdf/SWJaamas14.pdf, SWJaamas14, 1693-1694","tags":"publication","title":"AtomicOrchid: Human-Agent Collectives to the Rescue (Demostration)"},{"url":"//wufeng02.github.io/publication.html#WJaaai14","text":"Feng Wu and Nicholas R. Jennings, Regret-Based Multi-Agent Coordination with Uncertain Task Rewards, Many multi-agent coordination problems can be represented as DCOPs. Motivated by task allocation in disaster response, we extend standard DCOP models to consider uncertain task rewards where the outcome of completing a task depends onits current state, which is randomly drawn from unknown distributions. The goal of solving this problem is to find a solution for all agents that minimizes the overall worst-case loss. This is a challenging problem for centralized algorithms because the search space grows exponentially with the number of agents and is nontrivial for existing algorithms for standard DCOPs. To address this, we propose a novel decentralized algorithm that incorporates Max-Sum with iterative constraint generation to solve the problem by passing messages among agents. By so doing, our approach scales well and can solve instances of the task allocation problem with hundreds of agents and tasks., Quebec City, Canada, inproceedings, @inproceedings{WJaaai14,\n address = {Quebec City, Canada},\n author = {Feng Wu and Nicholas R. Jennings},\n booktitle = {Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI)},\n pages = {1492-1499},\n title = {Regret-Based Multi-Agent Coordination with Uncertain Task Rewards},\n year = {2014}\n}\n\n, 2014, doc/pdf/WJaaai14.pdf, WJaaai14, Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI), 1492-1499","tags":"publication","title":"Regret-Based Multi-Agent Coordination with Uncertain Task Rewards"},{"url":"//wufeng02.github.io/publication.html#BWCnips13","text":"Aijun Bai and Feng Wu and Xiaoping Chen, Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search, Monte-Carlo tree search (MCTS) has been drawing great interest in recent years for planning and learning under uncertainty. One of the key challenges is the trade-off between exploration and exploitation. To address this, we present a novel approach for MCTS using Bayesian mixture modeling and inference based Thompson sampling and apply it to the problem of online planning in MDPs. Our algorithm, named Dirichlet-NormalGamma MCTS (DNG-MCTS), models the uncertainty of the accumulated reward for actions in the search tree as a mixture of Normal distributions. We perform inferences on the mixture in Bayesian settings by choosing conjugate priors in the form of combinations of Dirichlet and NormalGamma distributions and select the best action at each decision node using Thompson sampling. Experimental results confirm that our algorithm advances the state-of-the-art UCT approach with better values on several benchmark problems., Lake Tahoe, United States, inproceedings, @inproceedings{BWCnips13,\n address = {Lake Tahoe, United States},\n author = {Aijun Bai and Feng Wu and Xiaoping Chen},\n booktitle = {Proceedings of the Advances in Neural Information Processing Systems (NIPS)},\n pages = {1646-1654},\n title = {Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search},\n year = {2013}\n}\n\n, 2013, doc/pdf/BWCnips13.pdf, BWCnips13, Proceedings of the Advances in Neural Information Processing Systems (NIPS), 1646-1654","tags":"publication","title":"Bayesian Mixture Modelling and Inference based Thompson Sampling in Monte-Carlo Tree Search"},{"url":"//wufeng02.github.io/publication.html#WZJijcai13","text":"Feng Wu and Shlomo Zilberstein and Nicholas R. Jennings, Monte-Carlo Expectation Maximization for Decentralized POMDPs, We address two significant drawbacks of state-of-the-art solvers of decentralized POMDPs (DEC-POMDPs): the reliance on complete knowledge of the model and limited scalability as the complexity of the domain grows. We extend a recently proposed approach for solving DEC-POMDPs via a reduction to the maximum likelihood problem, which in turn can be solved using EM. We introduce a model-free version of this approach that employs Monte-Carlo EM (MCEM). While a na?ve implementation of MCEM is inadequate in multiagent settings, we introduce several improvements in sampling that produce high-quality results on a variety of DEC-POMDP benchmarks, including large problems with thousands of agents., Beijing, China, inproceedings, @inproceedings{WZJijcai13,\n address = {Beijing, China},\n author = {Feng Wu and Shlomo Zilberstein and Nicholas R. Jennings},\n booktitle = {Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI)},\n pages = {397-403},\n title = {Monte-Carlo Expectation Maximization for Decentralized {POMDPs}},\n year = {2013}\n}\n\n, 2013, doc/pdf/WZJijcai13.pdf, WZJijcai13, Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI), 397-403","tags":"publication","title":"Monte-Carlo Expectation Maximization for Decentralized POMDPs"},{"url":"//wufeng02.github.io/publication.html#BWCaamas12","text":"Aijun Bai and Feng Wu and Xiaoping Chen, Online Planning for Large MDPs with MAXQ-like Decomposition (Extended Abstract), Markov decision processes (MDPs) provide an expressive framework for planning in stochastic domains. However, exactly solving a large MDP is often intractable due to the curse of dimensionality. Online algorithms help overcome the high computational complexity by avoiding computing a policy for each possible state. Hierarchical decomposition is another promising way to help scale MDP algorithms up to large domains by exploiting their underlying structure. In this paper, we present an effort on combining the benefits of a general hierarchical structure based on MAXQ value function decomposition with the power of heuristic and approximate techniques for developing an online planning framework, called MAXQ-OP. The proposed framework provides a principled approach for programming autonomous agents in a large stochastic domain. We have been conducting a long-term case-study with the RoboCup soccer simulation 2D domain, which is extremely larger than domains usually studied in literature, as the major benchmark to this research. The case-study showed that the agents developed with this framework and the related techniques reached outstanding performances, showing its high scalability to very large domains., Valencia, Spain, inproceedings, @inproceedings{BWCaamas12,\n address = {Valencia, Spain},\n author = {Aijun Bai and Feng Wu and Xiaoping Chen},\n booktitle = {Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},\n pages = {1215-1216},\n title = {Online Planning for Large {MDPs} with {MAXQ}-like Decomposition (Extended Abstract)},\n year = {2012}\n}\n\n, 2012, doc/pdf/BWCaamas12.pdf, BWCaamas12, Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 1215-1216","tags":"publication","title":"Online Planning for Large MDPs with MAXQ-like Decomposition (Extended Abstract)"},{"url":"//wufeng02.github.io/publication.html#BWCrobocup12","text":"Aijun Bai and Feng Wu and Xiaoping Chen, Towards a Principled Solution to Simulated Robot Soccer, The RoboCup soccer simulation 2D domain is a very large testbed for the research of planning and machine learning. It has competed in the annual world championship tournaments in the past 15 years. However it is still unclear that whether more principled techniques such as decision-theoretic planning take an important role in the success for a RoboCup 2D team. In this paper, we present a novel approach based on MAXQ-OP to automated planning in the RoboCup 2D domain. It combines the bene ts of a general hierarchical structure based on MAXQ value function decomposition with the power of heuristic and approximate techniques. The proposed framework provides a principled solution to programming autonomous agents in large stochastic domains. The MAXQ-OP framework has been implemented in our RoboCup 2D team, WrightEagle. The empirical results indicated that the agents developed with this framework and related techniques reached outstanding performances, showing its potential of scalability to very large domains., Mexico City, Mexico, inproceedings, @inproceedings{BWCrobocup12,\n address = {Mexico City, Mexico},\n author = {Aijun Bai and Feng Wu and Xiaoping Chen},\n booktitle = {Proceedings of the Robot Soccer World Cup XVI Symposium (RoboCup)},\n pages = {141-153},\n title = {Towards a Principled Solution to Simulated Robot Soccer},\n year = {2012}\n}\n\n, 2012, doc/pdf/BWCrobocup12.pdf, BWCrobocup12, Proceedings of the Robot Soccer World Cup XVI Symposium (RoboCup), 141-153","tags":"publication","title":"Towards a Principled Solution to Simulated Robot Soccer"},{"url":"//wufeng02.github.io/publication.html#WJCecai12","text":"Feng Wu and Nicholas R. Jennings and Xiaoping Chen, Sample-Based Policy Iteration for Constrained DEC-POMDPs, We introduce constrained DEC-POMDPsCan extension of the standard DEC-POMDPs including additional constraints to the optimality of the long-term reward. Constrained DEC-POMDPs present natural framework for modeling cooperative multi-agent problems with limited resources or multiple objectives. To solve constrained DEC-POMDPs, we propose a novel sample-based policy iteration algorithm. The algorithm builds up on multi-agent dynamic programming and benefits from several advantages of recentdeveloped DEC-POMDP algorithms. It improves the joint policy by solving a serial of standard nonlinear programs and thereby lends itself the power of existing NLP solvers. The experimental results confirm that the algorithm can efficiently solve constrained DECPOMDPs while the general DEC-POMDP algorithms fail. It outperforms the leading DEC-POMDP method with higher value and less chance of constraint violation., Montpellier, France, inproceedings, @inproceedings{WJCecai12,\n address = {Montpellier, France},\n author = {Feng Wu and Nicholas R. Jennings and Xiaoping Chen},\n booktitle = {Proceedings of the 20th European Conference on Artificial Intelligence (ECAI)},\n pages = {858-863},\n title = {Sample-Based Policy Iteration for Constrained {DEC-POMDPs}},\n year = {2012}\n}\n\n, 2012, doc/pdf/WJCecai12.pdf, WJCecai12, Proceedings of the 20th European Conference on Artificial Intelligence (ECAI), 858-863","tags":"publication","title":"Sample-Based Policy Iteration for Constrained DEC-POMDPs"},{"url":"//wufeng02.github.io/publication.html#Wustc11","text":"University of Science and Technology of China (USTC), Feng Wu, Decision-Theoretic Planning for Multi-Agent Systems, Wustc11, @phdthesis{Wustc11,\n author = {Feng Wu},\n school = {University of Science and Technology of China (USTC)},\n title = {Decision-Theoretic Planning for Multi-Agent Systems},\n year = {2011}\n}\n\n, 2011, phdthesis","tags":"publication","title":"Decision-Theoretic Planning for Multi-Agent Systems"},{"url":"//wufeng02.github.io/publication.html#WZCaij11","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Artificial Intelligence (AIJ), We propose an online algorithm for planning under uncertainty in multi-agent settings modeled as DEC-POMDPs. The algorithm helps overcome the high computational complexity of solving such problems offline. The key challenges in decentralized operation are to maintain coordinated behavior with little or no communication and, when communication is allowed, to optimize value with minimal communication. The algorithm addresses these challenges by generating identical conditional plans based on common knowledge and communicating only when history inconsistency is detected, allowing communication to be postponed when necessary. To be suitable for online operation, the algorithm computes good local policies using a new and fast local search method implemented using linear programming. Moreover, it bounds the amount of memory used at each step and can be applied to problems with arbitrary horizons. The experimental results confirm that the algorithm can solve problems that are too large for the best existing offline planning algorithms and it outperforms the best online method, producing much higher value with much less communication in most cases. The algorithm also proves to be effective when the communication channel is imperfect (periodically unavailable). These results contribute to the scalability of decision-theoretic planning in multi-agent settings., Online Planning for Multi-Agent Systems with Bounded Communication, 2, article, 175, @article{WZCaij11,\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n journal = {Artificial Intelligence (AIJ)},\n number = {2},\n pages = {487-511},\n title = {Online Planning for Multi-Agent Systems with Bounded Communication},\n volume = {175},\n year = {2011}\n}\n\n, 2011, doc/pdf/WZCaij11.pdf, WZCaij11, 487-511","tags":"publication","title":"Online Planning for Multi-Agent Systems with Bounded Communication"},{"url":"//wufeng02.github.io/publication.html#WZCijcai11","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Online Planning for Ad Hoc Autonomous Agent Teams, We propose a novel online planning algorithm for ad hoc team settings' challenging situations in which an agent must collaborate with unknown teammates without prior coordination. Our approach is based on constructing and solving a series of stage games, and then using biased adaptive play to choose actions. The utility function in each stage game is estimated via Monte-Carlo tree search using the UCT algorithm. We establish analytically the convergence of the algorithm and show that it performs well in a variety of ad hoc team domains., Barcelona, Spain, inproceedings, @inproceedings{WZCijcai11,\n address = {Barcelona, Spain},\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n booktitle = {Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI)},\n pages = {439-445},\n title = {Online Planning for Ad Hoc Autonomous Agent Teams},\n year = {2011}\n}\n\n, 2011, doc/pdf/WZCijcai11.pdf, WZCijcai11, Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI), 439-445","tags":"publication","title":"Online Planning for Ad Hoc Autonomous Agent Teams"},{"url":"//wufeng02.github.io/publication.html#WZCaaai10","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Trial-Based Dynamic Programming for Multi-Agent Planning, Trial-based approaches offer an efficient way to solve singleagent MDPs and POMDPs. These approaches allow agents to focus their computations on regions of the environment they encounter during the trials, leading to significant computational savings. We present a novel trial-based dynamic programming (TBDP) algorithm for DEC-POMDPs that extends these benefits to multi-agent settings. The algorithm uses trial-based methods for both belief generation and policy evaluation. Policy improvement is implemented efficiently using linear programming and a sub-policy reuse technique that helps bound the amount of memory. The results show that TBDP can produce significant value improvements and is much faster than the best existing planning algorithms., Atlanta, United States, inproceedings, @inproceedings{WZCaaai10,\n address = {Atlanta, United States},\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n booktitle = {Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI)},\n pages = {908-914},\n title = {Trial-Based Dynamic Programming for Multi-Agent Planning},\n year = {2010}\n}\n\n, 2010, doc/pdf/WZCaaai10.pdf, WZCaaai10, Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI), 908-914","tags":"publication","title":"Trial-Based Dynamic Programming for Multi-Agent Planning"},{"url":"//wufeng02.github.io/publication.html#WZCaamas10","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Point-Based Policy Generation for Decentralized POMDPs, Memory-bounded techniques have shown great promise in solving complex multi-agent planning problems modeled as DEC-POMDPs. Much of the performance gains can be attributed to pruning techniques that alleviate the complexity of the exhaustive backup step of the original MBDP algorithm. Despite these improvements, state-of-the-art algorithms can still handle a relative small pool of candidate policies, which limits the quality of the solution in some benchmark problems. We present a new algorithm, Point- Based Policy Generation, which avoids altogether searching the entire joint policy space. The key observation is that the best joint policy for each reachable belief state can be constructed directly, instead of producing first a large set of candidates. We also provide an efficient approximate implementation of this operation. The experimental results show that our solution technique improves the performance significantly in terms of both runtime and solution quality., Toronto, Canada, inproceedings, @inproceedings{WZCaamas10,\n address = {Toronto, Canada},\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)},\n pages = {1307-1314},\n title = {Point-Based Policy Generation for Decentralized {POMDPs}},\n year = {2010}\n}\n\n, 2010, doc/pdf/WZCaamas10.pdf, WZCaamas10, Proceedings of the 9th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), 1307-1314","tags":"publication","title":"Point-Based Policy Generation for Decentralized POMDPs"},{"url":"//wufeng02.github.io/publication.html#WZCuai10","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Rollout Sampling Policy Iteration for Decentralized POMDPs, We present decentralized rollout sampling policy iteration (DecRSPI)Ca new algorithm for multiagent decision problems formalized as DECPOMDPs. DecRSPI is designed to improve scalability and tackle problems that lack an explicit model. The algorithm uses Monte-Carlo methods to generate a sample of reachable belief states. Then it computes a joint policy for each belief state based on the rollout estimations. A new policy representation allows us to represent solutions compactly. The key benefits of the algorithm are its linear time complexity over the number of agents, its bounded memory usage and good solution quality. It can solve larger problems that are intractable for existing planning algorithms. Experimental results confirm the effectiveness and scalability of the approach., Catalina, United States, inproceedings, @inproceedings{WZCuai10,\n address = {Catalina, United States},\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n booktitle = {Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI)},\n pages = {666-673},\n title = {Rollout Sampling Policy Iteration for Decentralized {POMDPs}},\n year = {2010}\n}\n\n, 2010, doc/pdf/WZCuai10.pdf, WZCuai10, Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI), 666-673","tags":"publication","title":"Rollout Sampling Policy Iteration for Decentralized POMDPs"},{"url":"//wufeng02.github.io/publication.html#WZCicaps09","text":"Feng Wu and Shlomo Zilberstein and Xiaoping Chen, Multi-Agent Online Planning with Communication, We propose an online algorithm for planning under uncertainty in multi-agent settings modeled as DEC-POMDPs. The algorithm helps overcome the high computational complexity of solving such problems off-line. The key challenge is to produce coordinated behavior using little or no communication. When communication is allowed but constrained, the challenge is to produce high value with minimal communication. The algorithm addresses these challenges by communicating only when history inconsistency is detected, allowing communication to be postponed if necessary. Moreover, it bounds the memory usage at each step and can be applied to problems with arbitrary horizons. The experimental results confirm that the algorithm can solve problems that are too large for the best existing off-line planning algorithms and it outperforms the best online method, producing higher value with much less communication in most cases., Thessaloniki, Greece, inproceedings, @inproceedings{WZCicaps09,\n address = {Thessaloniki, Greece},\n author = {Feng Wu and Shlomo Zilberstein and Xiaoping Chen},\n booktitle = {Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS)},\n pages = {321-329},\n title = {Multi-Agent Online Planning with Communication},\n year = {2009}\n}\n\n, 2009, doc/pdf/WZCicaps09.pdf, WZCicaps09, Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS), 321-329","tags":"publication","title":"Multi-Agent Online Planning with Communication"},{"url":"//wufeng02.github.io/publication.html#WCrobocup07","text":"Feng Wu and Xiaoping Chen, Solving Large-Scale and Sparse-Reward DEC-POMDPs with Correlation-MDPs, Within a group of cooperating agents the decision making of an individual agent depends on the actions of the other agents. A lot of effort has been made to solve this problem with additional assumptions on the communication abilities of agents. However, in some realworld applications, communication is limited and the assumptions are rarely satisfied. An alternative approach newly developed is to employ a correlation device to correlate the agents' behavior without exchanging information during execution. In this paper, we apply correlation device to large-scale and spare-reward domains. As a basis we use the framework of infinite-horizon DEC-POMDPs which represent policies as joint stochastic finite-state controllers. To solve any problem of this kind, a correlation device is firstly calculated by solving Correlation Markov Decision Processes (Correlation-MDPs) and then used to improve the local controller for each agent. By using this method, we are able to achieve a tradeoff between computational complexity and the quality of the approximation. In addition, we demonstrate that, adversarial problems can be solved by encoding the information of opponents'ddate behavior in the correlation device.We have successfully implemented the proposed method into our 2D simulated robot soccer team and the performance in RoboCup-2006 was encouraging., Atlanta, United States, inproceedings, @inproceedings{WCrobocup07,\n address = {Atlanta, United States},\n author = {Feng Wu and Xiaoping Chen},\n booktitle = {Proceedings of the Robot Soccer World Cup XI Symposium (RoboCup)},\n pages = {208-219},\n title = {Solving Large-Scale and Sparse-Reward {DEC-POMDPs} with Correlation-{MDPs}},\n year = {2007}\n}\n\n, 2007, doc/pdf/WCrobocup07.pdf, WCrobocup07, Proceedings of the Robot Soccer World Cup XI Symposium (RoboCup), 208-219","tags":"publication","title":"Solving Large-Scale and Sparse-Reward DEC-POMDPs with Correlation-MDPs"},{"url":"//wufeng02.github.io/publication.html#BFWrobocup05","text":"Peng Bai and Changjie Fan and Feng Wu and Xiaoping Chen, Proceedings of Robot Soccer World Cup IX Symposium (RoboCup), WrightEagle 2D Simulation Team 2005, BFWrobocup05, @inproceedings{BFWrobocup05,\n author = {Peng Bai and Changjie Fan and Feng Wu and Xiaoping Chen},\n booktitle = {Proceedings of Robot Soccer World Cup IX Symposium (RoboCup)},\n title = {WrightEagle 2D Simulation Team 2005},\n year = {2005}\n}\n\n, 2005, inproceedings","tags":"publication","title":"WrightEagle 2D Simulation Team 2005"}]}